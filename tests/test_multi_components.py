# import os, sys
# ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "./"))
# sys.path.insert(0, ROOT)
# # print(sys.path)

import pytest
import operator
import numpy as np
from lmfit_global import LmfitGlobal
from lmfit_global.utils import parameters, lineshapes
from lmfit_global.utils.builders import GlobalFitBuilder


VALID_CONNECTORS = {
    '+': operator.add,
    '-': operator.sub,
    '*': operator.mul,
    '/': operator.truediv,
}


def make_builder(x, y, models, connect=None):
    """Create and configure a GlobalFitBuilder for lmfit_global.

    This function initializes a GlobalFitBuilder with the provided data
    and attaches one or more model components. Optionally, model components
    can be connected using binary operators.

    Args:
        x (array-like): 1D array of x values.
        y (array-like): 2D array of y values with shape (Npoints, Ndatasets).
        models (list of tuple): Each tuple defines a model component and must be either:
            - (func, init_params)
            - (func, init_params, func_kws)
                where `func` is a callable model function, `init_params` is a
                parameter specification dictionary, and `func_kws` is an optional
                dictionary of keyword arguments passed to the model function.
        connect (str or list of str, optional): Binary operator(s) defining how to combine 
            model components. Examples: "+", ["+", "*"]. If None, components are unconnected.

    Returns:
        GlobalFitBuilder:
            A configured GlobalFitBuilder instance ready to be built.
    """
    builder = GlobalFitBuilder().set_data(x, y)

    for model in models:
        if len(model) == 2:
            func, init = model
            func_kws = {}
        elif len(model) == 3:
            func, init, func_kws = model
        else:
            raise ValueError("Model must be (func, init[, func_kws])")

        builder.add_model(func, init, func_kws=func_kws)

    if connect is not None:
        builder.connect(connect)

    return builder


def generate_param_ensemble(param_generators, N):
    """Generate an ensemble of parameter dictionaries for multiple datasets.

    Each dataset receives one parameter dictionary per model component,
    generated by calling the corresponding parameter generator.

    Args:
        param_generators (list of callable): Each callable returns a parameter dictionary 
            for a model component.
        N (int): Number of datasets to generate.

    Returns:
        list of list of dict:
            Nested list with shape [N][Ncomponents], where each inner dict
            contains parameters for one model component.
    """
    return [
        [gen() for gen in param_generators]
        for _ in range(N)
    ]


def composite_from_funcs(x, func_list, param_dicts, connect, operator_map):
    """Evaluate and combine multiple functions into a composite model.

    Each function is evaluated with its corresponding parameter dictionary,
    then combined using the specified connectors.

    Args:
        x (array-like): 1D array of x values.
        func_list (list of callable): Model functions to evaluate.
        param_dicts (list of dict): Parameter dictionaries corresponding to each 
            function.
        connect (list of str): Binary operators defining how to combine function 
            outputs.
        operator_map (dict): Mapping of operator symbols (e.g., "+", "*") to Python 
            callables.

    Returns:
        ndarray:
            Composite model evaluated over `x`.
    """
    values = [
        func(x, **params)
        for func, params in zip(func_list, param_dicts)
    ]

    return LmfitGlobal.reduce_to_composite(
        items=values,
        ops=connect,
        operator_map=operator_map,
    )


def composite_ensemble(
    x,
    func_list,
    param_generators,
    N,
    connect,
    operator_map,
):
    """Generate a composite model for an ensemble of datasets.

    For each dataset, parameters are generated, functions are evaluated,
    and combined into a composite signal. The result is stacked column-wise.

    Args:
        x (array-like): 1D array of x values.
        func_list (list of callable): Model functions.
        param_generators (list of callable): Functions generating parameter dictionaries.
        N (int): Number of datasets.
        connect (list of str): Binary operators for combining model components.
        operator_map (dict): Mapping of operator symbols to callables.

    Returns:
        ndarray:
            Array of shape (len(x), N) containing all generated datasets.
    """
    ensemble_params = generate_param_ensemble(param_generators, N)

    return np.column_stack([
        composite_from_funcs(
            x, func_list, param_dicts, connect, operator_map
        )
        for param_dicts in ensemble_params
    ])



def get_datasets(
    x,
    func_list,
    param_generators,
    N,
    connect,
    noise_scale=1e-3,
    rng=None,
):
    """Generate noisy synthetic datasets from composite models.

    This function creates multiple datasets by evaluating composite models
    and optionally adding Gaussian noise.

    Args:
        x (array-like): 1D array of x values.
        func_list (list of callable): Model functions.
        param_generators (list of callable): Parameter generators for each model component.
        N (int): Number of datasets.
        connect (list of str): Binary operators for combining components.
        noise_scale (float, optional): Standard deviation of added Gaussian noise.
        rng (numpy.random.Generator, optional): Random number generator. If None, a default 
            generator is used.

    Returns:
        ndarray:
            Array of shape (len(x), N) containing noisy datasets.
    """
    if rng is None:
        rng = np.random.default_rng()

    y = composite_ensemble(
        x,
        func_list,
        param_generators,
        N,
        connect,
        operator_map=VALID_CONNECTORS,
    )

    if noise_scale > 0:
        y = y + rng.normal(scale=noise_scale, size=y.shape)

    return y


def get_init_params(params):
    """Normalize parameter specifications for lmfit initialization.

    Converts a simple parameter dictionary into a fully expanded
    lmfit-compatible initialization dictionary, filling in defaults
    where values are missing.

    Args:
        params (dict): Dictionary of parameter values or partial specifications.

    Returns:
        dict:
            Normalized initialization parameters suitable for lmfit.
    """
    pardict = parameters.normalize_parameter_specs(params)

    init_params = {}
    for name, spec in pardict.items():
        final = {}
        for key, default in parameters._LMFIT_INIT_PARAMETER_DEFAULTS.items():
            val = spec.get(key, parameters._UNSET)
            final[key] = default if val is parameters._UNSET else val
        init_params[name] = final

    return init_params


def build_items(
    xy,
    functions,
    connectors=None,
    xrange=None,
):
    """Build an lmfit_global-compatible items dictionary.

    This is a generic helper for constructing multi-component,
    multi-dataset fit specifications in the format required by
    `LmfitGlobal`.

    Args:
        xy (ndarray): 2D array with shape (Npoints, 1 + Ndatasets).
            First column is x, remaining columns are y datasets.
        functions (list of dict): Each dictionary defines a model component and must contain:
            - 'func_name': callable
            - 'init_params': dict
                Optional:
                    - 'func_kws': dict
        connectors (list of str, optional): Binary operators ('+', '-', '*', '/') connecting model 
            components. Length must be len(functions) - 1.
        xrange (tuple of float, optional): Optional (xmin, xmax) range for fitting.

    Returns:
        dict:
            Items dictionary ready to be passed into `LmfitGlobal`.

    Raises:
        ValueError:
            If the number of connectors does not match the number of functions.
        KeyError:
            If required keys are missing in function definitions.
    """

    if connectors is None:
        connectors = []

    if connectors and len(connectors) != len(functions) - 1:
        raise ValueError(
            "Number of connectors must be len(functions) - 1"
        )

    # Validate functions
    normalized_funcs = []
    for i, f in enumerate(functions):
        if "func_name" not in f:
            raise KeyError(f"functions[{i}] missing 'func_name'")
        if "init_params" not in f:
            raise KeyError(f"functions[{i}] missing 'init_params'")

        normalized_funcs.append({
            "func_name": f["func_name"],
            "init_params": f["init_params"],
            "func_kws": f.get("func_kws", {}),
        })

    items = {
        "data": {
            "xy": xy,
            "xrange": xrange,
        },
        "functions": {
            "theory": normalized_funcs,
            "theory_connectors": connectors,
        },
    }

    return items

def _isclose(name, expected_value, fit_value, atol=0.1, rtol=0.05):
    """isclose with error message"""
    assert np.isclose(expected_value, fit_value, atol=atol, rtol=rtol), \
        f"bad value for {name}: expected {expected_value}, got {fit_value}"
    

# x = np.linspace(0, 10, 201)
                                                
# test_gaussian = dict(amplitude=8.5, center=6.66, sigma=0.68)

# y = lineshapes.gaussian(x, **test_gaussian)
# y += np.random.normal(scale=0.1, size=x.size)

# xy = np.column_stack([x, y])

# items = build_items(
#     xy=xy,
#     functions=[
#         {
#             "func_name": lineshapes.gaussian,
#             "init_params": {
#                 "amplitude": {"value": 5},
#                 "center": {"value": 5},
#                 "sigma": {"value": 1},
#             },
#         }
#     ],
# )

# items



def testSingleGaussianLinear():
    np.random.seed(0)
    x = np.linspace(0, 10, 201)
                                                   
    test_gaussian = dict(amplitude=8.5, center=6.66, sigma=0.68)
    test_linear   = dict(slope=0.25, intercept=-1.0)

    y = lineshapes.gaussian(x, **test_gaussian)
    y += lineshapes.linear(x, **test_linear)
    y += np.random.normal(scale=0.1, size=x.size)

    xy = np.column_stack([x, y])

    items = build_items(
        xy=xy,
        functions=[
            {
                "func_name": lineshapes.gaussian,
                "init_params": get_init_params(test_gaussian),
            },
            {
                "func_name": lineshapes.linear,
                "init_params": get_init_params(test_linear),
            },
        ],
        connectors=["+"],
    )


    lg = LmfitGlobal(items)
    lg.fit(verbose=True)
    # lg.plot()

    assert lg.result.success
    assert lg.result.redchi < 2.0

    fit_params = lg.result.params

    _isclose("gaussian amplitude", test_gaussian["amplitude"], fit_params["c0_amplitude_0"].value)
    _isclose("gaussian center", test_gaussian["center"], fit_params["c0_center_0"].value)
    _isclose("gaussian sigma", test_gaussian["sigma"], fit_params["c0_sigma_0"].value)
    _isclose("linear slope", test_linear["slope"], fit_params["c1_slope_0"].value)
    _isclose("linear intercept", test_linear["intercept"], fit_params["c1_intercept_0"].value)

    return lg



def testSingleGaussianLorentzian():
    np.random.seed(0)
    x = np.linspace(0, 20.0, 601)

    test_gaussian   = dict(amplitude=21.0, center=6.1, sigma=1.2)
    test_lorentzian = dict(amplitude=10.0, center=9.6, sigma=1.3)

    y = (
        lineshapes.gaussian(x, **test_gaussian)
        + lineshapes.lorentzian(x, **test_lorentzian)
        + np.random.normal(scale=0.1, size=x.size)
    )

    xy = np.column_stack([x, y])

    items = build_items(
        xy=xy,
        functions=[
            {
                "func_name": lineshapes.gaussian,
                "init_params": get_init_params(test_gaussian),
            },
            {
                "func_name": lineshapes.lorentzian,
                "init_params": get_init_params(test_lorentzian),
            },
        ],
        connectors=["+"],
    )

    lg = LmfitGlobal(items)
    lg.fit(verbose=True)
    # lg.plot()

    assert lg.result.success
    assert lg.result.redchi < 2.0

    fit_params = lg.result.params

    _isclose("gaussian amplitude", test_gaussian["amplitude"], fit_params["c0_amplitude_0"].value)
    _isclose("gaussian center", test_gaussian["center"], fit_params["c0_center_0"].value)
    _isclose("gaussian sigma", test_gaussian["sigma"], fit_params["c0_sigma_0"].value)
    _isclose("lorentzian amplitude", test_lorentzian["amplitude"], fit_params["c1_amplitude_0"].value)
    _isclose("lorentzian center", test_lorentzian["center"], fit_params["c1_center_0"].value)
    _isclose("lorentzian sigma", test_lorentzian["sigma"], fit_params["c1_sigma_0"].value)    

    return lg



def testmuSRWTF():
    np.random.seed(0)
    t = np.linspace(0, 6, 500)

    gamma_mu = 0.0135538817  # MHz/G

    test_asy = dict(A=0.2357)
    test_exp = dict(lam=0.02)
    test_cos = dict(phi=-6.0, nu=gamma_mu*30)

    y = (
        lineshapes.asymmetry(t, **test_asy)
        * lineshapes.simplExpo(t, **test_exp)
        * lineshapes.TFieldCos(t, **test_cos)
        + np.random.normal(scale=0.01, size=t.size)
    )

    xy = np.column_stack([t, y])

    init_asy = get_init_params(test_asy)
    init_asy["A"].update(vary=True)

    init_exp = get_init_params(test_exp)
    init_exp["lam"].update(min=0.0, max=0.2)

    init_cos = get_init_params(test_cos)
    # init_cos["phi"].update(vary=True, value=0.0)
    init_cos["nu"].update(min=gamma_mu*20,max=gamma_mu*40)

    items = build_items(
        xy=xy,
        functions=[
            {"func_name": lineshapes.asymmetry, "init_params": init_asy},
            {"func_name": lineshapes.simplExpo, "init_params": init_exp},
            {"func_name": lineshapes.TFieldCos, "init_params": init_cos},
        ],
        connectors=["*", "*"],
    )

    lg = LmfitGlobal(items)
    lg.fit(verbose=True)
    # lg.plot()

    assert lg.result.success
    assert lg.result.redchi < 2

    fit_params = lg.result.params

    _isclose("asymmetry amplitude", test_asy["A"], fit_params["c0_A_0"].value)
    _isclose("simple exponential decay", test_exp["lam"], fit_params["c1_lam_0"].value)
    _isclose("precession phase", test_cos["phi"], fit_params["c2_phi_0"].value, atol=0.2)
    _isclose("precession frequency (MHz)", test_cos["nu"], fit_params["c2_nu_0"].value)

    return lg


def testMultiGaussianLinear():
    def gaussian_params(rng):
        return dict(
            amplitude=rng.uniform(2.0, 10.0),
            center=rng.uniform(2.0, 6.0),
            sigma=rng.uniform(0.2, 1.2),
        )

    def linear_params(rng):
        return dict(
            intercept=rng.uniform(-1.0, -0.9),
            slope=rng.uniform(0.21, 0.25),
        )


    rng = np.random.default_rng(1234)  # random number generator
    x = np.linspace(0, 10, 501)        # x-grid
    N = 5                              # number of datasets 

    param_generators = [
        lambda: gaussian_params(rng),
        lambda: linear_params(rng),
    ]   # input values for random datasets
    y = get_datasets(
        x,
        func_list=[lineshapes.gaussian, lineshapes.linear],
        param_generators=param_generators,
        N=N,
        connect=["+"],
        noise_scale=0.02,
        rng=rng
    )

    # -- deterministic init params ---
    init_params = [
        get_init_params(dict(amplitude=5, center=4, sigma=0.5)),
        get_init_params(dict(intercept=-0.95, slope=0.23)),
    ]
    # print(init_params)

    # init_params[0]["center"]["value"] = 4
    init_params[0]["amplitude"].update(value=5, min=0.1, max=+np.inf)
    init_params[0]["center"].update(value=4)
    init_params[0]["sigma"].update(value=0.5, min=0.2, max=1.5)

    builder = make_builder(
        x, y,
        models=[
            (lineshapes.gaussian, init_params[0]),
            (lineshapes.linear,   init_params[1]),
        ],
        connect="+",
    )

    lg = LmfitGlobal(builder.build())
    lg.fit(verbose=True)
    # lg.plot()

    assert lg.result.success
    assert y.shape == (lg.N, lg.ny)
    assert lg.ny == N
    assert lg.result.nfev > 10
    # print(lg.result.chisqr, lg.result.redchi)
    # assert lg.result.nvarys == lg.ny * 5
    # assert lg.result.chisqr > 0.2
    # assert 0.1 < lg.result.redchi < 2.0   # changes with N datasets

    for j in range(lg.ny):
        amp = lg.result.params[f'c0_amplitude_{j}']
        cen = lg.result.params[f'c0_center_{j}']
        sig = lg.result.params[f'c0_sigma_{j}']
        slope = lg.result.params[f'c1_slope_{j}']
        intercept = lg.result.params[f'c1_intercept_{j}']

        assert amp.value > 0
        assert 0.2 <= sig.value <= 1.5
        assert 0.18 < slope.value < 0.28
        assert -1.1 < intercept.value < -0.8

    return lg



def _run_step_test(step_form=None):
    """
    Internal helper to test step + linear model with different step forms.

    Args:
        step_form (str or None): Step functional form. If None, default step form 
        is used (erf). 
        Supported values: None, 'erf', 'logistic', 'atan', 'arctan', or 'linear'
    Returns:
        lg : LmfitGlobal
            Fitted model instance
    """

    step_form = step_form or "erf"   # <-- KEY LINE

    def step_params(rng):
        return dict(
            amplitude=110.0 + rng.normal(0, 2.0),
            center=2.5 + rng.normal(0, 0.15),
            sigma=0.15,
        )

    def linear_params(rng):
        return dict(
            slope=2.22 + rng.normal(0, 0.02),
            intercept=12.0 + rng.normal(0, 0.5),
        )

    rng = np.random.default_rng(1234)

    x = np.linspace(0, 10, 201)
    N = 4  # number of datasets

    param_generators = [
        lambda: step_params(rng),
        lambda: linear_params(rng),
    ]

    y = get_datasets(
        x,
        func_list=[lineshapes.step, lineshapes.linear],
        param_generators=param_generators,
        N=N,
        connect=["+"],
        noise_scale=0.9,
        rng=rng,
    )

    init_params = [
        get_init_params(dict(amplitude=100, center=2.5, sigma=0.2)),
        get_init_params(dict(slope=2.0, intercept=10.0)),
    ]

    # parameter constraints
    init_params[0]["amplitude"].update(min=10)
    init_params[0]["sigma"].update(min=0.05, max=0.5)
    init_params[1]["slope"].update(min=1.5, max=3.0)

    # --- build models ---
    if step_form is None:
        models = [
            (lineshapes.step,   init_params[0]),
            (lineshapes.linear, init_params[1]),
        ]
    else:
        models = [
            (lineshapes.step,   init_params[0], {"form": step_form}),
            (lineshapes.linear, init_params[1]),
        ]

    builder = make_builder(
        x, y,
        models=models,
        connect="+",
    )

    lg = LmfitGlobal(builder.build())
    lg.fit(verbose=True)
    # lg.plot()

    # -----------------------
    # Core assertions
    # -----------------------
    assert lg.result.success
    assert y.shape == (lg.N, lg.ny)
    assert lg.ny == N
    assert lg.result.nfev > 20
    assert lg.result.chisqr > 0

    # -----------------------
    # Parameter sanity checks
    # -----------------------
    for j in range(N):
        amp = lg.result.params[f"c0_amplitude_{j}"].value
        cen = lg.result.params[f"c0_center_{j}"].value
        sig = lg.result.params[f"c0_sigma_{j}"].value
        slope = lg.result.params[f"c1_slope_{j}"].value
        intercept = lg.result.params[f"c1_intercept_{j}"].value

        assert 80 < amp < 140
        assert 1.8 < cen < 3.2
        assert 0.05 <= sig <= 0.5
        assert 1.8 < slope < 2.6
        assert 5 < intercept < 25

    return lg


def testStepmodel_erf():
    """
    Step model using default ERF form.
    """
    lg = _run_step_test(step_form=None)
    return lg


def testStepmodel_linear():
    """
    Step model using explicit LINEAR form.
    """
    lg = _run_step_test(step_form="linear")
    return lg


def testStepmodel_logistic():
    """
    Step model using explicit LINEAR form.
    """
    lg = _run_step_test(step_form="logistic")
    return lg
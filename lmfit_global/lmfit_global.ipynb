{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a020fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import copy\n",
    "import logging\n",
    "import inspect\n",
    "import operator\n",
    "import textwrap\n",
    "import itertools\n",
    "import numpy as np\n",
    "import functools as ft\n",
    "\n",
    "# --- IMPORT SOME UTILS FROM GLOBUTILS\n",
    "from globutils import (\n",
    "    get_reducer, \n",
    "    propagate_err, \n",
    "    alphanumeric_sort,\n",
    "    getfloat_key, \n",
    "    getfloat_attr, \n",
    "    gformat,\n",
    "    r2_score_util,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0cc8f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configure logging once, ideally at the start of your program ---\n",
    "format='%(message)s'   # only show the message itself\n",
    "format='%(levelname)s | %(message)s'\n",
    "format='%(levelname)s: %(message)s'\n",
    "# format='%(asctime)s | %(levelname)s | %(message)s'\n",
    "# format='%(asctime)s | %(levelname)s | %(name)s | %(funcName)s | %(message)s'\n",
    "datefmt=None\n",
    "# datefmt='%Y-%m-%d %H:%M:%S'\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=format,\n",
    "    datefmt=datefmt,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# # --- Example: log CPU count ---\n",
    "# CPU_COUNT = os.cpu_count()\n",
    "# logger.info(f'The number of CPUs: {CPU_COUNT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe104e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- The package lmfit is a MUST\n",
    "try:\n",
    "    import lmfit\n",
    "except ImportError:\n",
    "    msg =  f'lmfit is required but not installed. Please install it with `pip install lmfit`...'\n",
    "    logger.error(msg)\n",
    "    raise ImportError(msg)\n",
    "\n",
    "try:\n",
    "    import matplotlib \n",
    "    _HAS_MATPLOTLIB = True\n",
    "except Exception:\n",
    "    _HAS_MATPLOTLIB = False\n",
    "    \n",
    "try:\n",
    "    import numdifftools \n",
    "    HAS_NUMDIFFTOOLS = True\n",
    "except ImportError:\n",
    "    HAS_NUMDIFFTOOLS = False\n",
    "\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    _HAS_TQDM = True\n",
    "except Exception:\n",
    "    _HAS_TQDM = False\n",
    "\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import r2_score as rsq\n",
    "except ImportError:\n",
    "    from globutils import r2_score_util as rsq\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import r2_score\n",
    "except ImportError:\n",
    "    r2_score = None\n",
    "\n",
    "\n",
    "def _ensureMatplotlib(function):\n",
    "    if _HAS_MATPLOTLIB:\n",
    "        @ft.wraps(function)\n",
    "        def wrapper(*args, **kws):\n",
    "            return function(*args, **kws)\n",
    "        return wrapper\n",
    "\n",
    "    def no_op(*args, **kwargs):\n",
    "        print('matplotlib module is required for plotting the results')\n",
    "    return no_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66294fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fbf94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LmfitGlobal:\n",
    "    _valid_connectors = ('+', '-', '*', '/')\n",
    "    _valid_connectors_dict = {\n",
    "        '+': operator.add,\n",
    "        '-': operator.sub,\n",
    "        '*': operator.mul,\n",
    "        '/': operator.truediv,\n",
    "    }\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate_function(func, x, params, prefix, i, func_kws=None):\n",
    "        \"\"\"Evaluate a single function with parameters from lmfit and `func` keyward arguments (if any).\n",
    "\n",
    "        Args:\n",
    "            func (callable): The function to evaluate\n",
    "            x (array, list of floats): Array-like of x data\n",
    "            params (lmfit.Parameters): Contains the Parameters for the model.\n",
    "            prefix (str): Prefix for the function `func` (e.g. 'c0_', 'c1_').\n",
    "            i (int): Index for dataset (e.g. 0 for first dataset).\n",
    "            func_kws (dict, optional): Additional keyword arguments to pass to model function. \n",
    "                Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: Evaluated function `func` values.\n",
    "        \"\"\"\n",
    "        if func_kws is None:\n",
    "            func_kws = {}\n",
    "\n",
    "        x = np.array(x)\n",
    "\n",
    "        # --- Get ordered function parameters ---\n",
    "        fn_pars = list(inspect.signature(func).parameters.keys())\n",
    "        argnames = fn_pars[1:]  # skip first (x variable)\n",
    "\n",
    "        kwargs = {}\n",
    "        for name in argnames:\n",
    "            param_key = f'{prefix}{name}_{i}'\n",
    "            if param_key in params:\n",
    "                kwargs[name] = params[param_key].value\n",
    "            elif name in func_kws:\n",
    "                kwargs[name] = func_kws[name]\n",
    "            # else: leave default\n",
    "            else:\n",
    "                pass # IS THIS OKAY!?\n",
    "\n",
    "        return func(x, **kwargs)\n",
    "    \n",
    "    \n",
    "    ### apply_operators  # --- OLD NAME ---\n",
    "    @staticmethod\n",
    "    def reduce_with_operators(items, ops, operator_map):\n",
    "        \"\"\"Reduce a sequence of items into a composite using operators.\n",
    "\n",
    "        Args:\n",
    "            items (list): Sequence of items to combine.\n",
    "            ops (list of str): Operators of length len(items)-1.\n",
    "            operator_map (dict): Mapping of operator symbols to functions (e.g. {'+': operator.add}).\n",
    "\n",
    "        Returns:\n",
    "            obj (object): Composite result after applying operators.\n",
    "        \"\"\"\n",
    "        obj = ft.reduce(\n",
    "            lambda x, y: operator_map[y[1]](x, y[0]),\n",
    "            zip(items[1:], ops),\n",
    "            items[0]\n",
    "            )\n",
    "        return obj\n",
    "    \n",
    "\n",
    "    # @staticmethod\n",
    "    # def _format_callable(func):\n",
    "    #     \"\"\"Return a string like 'func(arg1, arg2, ...)' for a callable.\"\"\"\n",
    "    #     sig = inspect.signature(func)\n",
    "    #     args = ', '.join(sig.parameters.keys())\n",
    "    #     return f'{func.__name__}({args})'\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def build_expression(funcs, operators):\n",
    "        \"\"\"Build a human-readable expression string from functions and operators.\n",
    "\n",
    "        Args:\n",
    "            funcs (list): list of callable functions to describe \n",
    "                (e.g., lmfit.Model.func or any callable).\n",
    "            operators (list of str): Operators ('+', '-', '*', '/') of length len(funcs)-1.\n",
    "\n",
    "        Returns:\n",
    "            expr (str): String representation of the composite function with arguments.\n",
    "        \"\"\"\n",
    "        # if len(operators) != len(funcs) - 1:\n",
    "        #     raise ValueError('operators must have length len(funcs)-1')\n",
    "\n",
    "        def _format_callable(func):\n",
    "            \"\"\"Return a string like 'func(arg1, arg2, ...)' for a callable.\"\"\"\n",
    "            sig = inspect.signature(func)\n",
    "            args = ', '.join(sig.parameters.keys())\n",
    "            return f'{func.__name__}({args})'\n",
    "    \n",
    "        parts = []\n",
    "        for func, op in itertools.zip_longest(funcs, operators, fillvalue=''):\n",
    "            parts.append(_format_callable(func))\n",
    "            if op:\n",
    "                parts.append(op)\n",
    "\n",
    "        return ' '.join(parts)\n",
    "\n",
    "    @staticmethod\n",
    "    def pretty_expr(expr, line_style=\"#\", width=80):\n",
    "        \"\"\"Log a boxed expression using logger.info(), similar to print_in_box() above.\n",
    "\n",
    "        Args:\n",
    "            expr (str): The expression string to display.\n",
    "            line_style (str, optional):  Character(s) used for the box border default to '#'.\n",
    "            width (int, optional): Maximum width of the box default to 80.\n",
    "        \"\"\"\n",
    "        # Wrap text to fit inside the box\n",
    "        wrapped = textwrap.wrap(expr, width=width - 4)\n",
    "\n",
    "        # Determine box width\n",
    "        box_width = max(len(line) for line in wrapped) + 4\n",
    "\n",
    "        # Top border\n",
    "        logger.info(line_style * box_width)\n",
    "\n",
    "        # Middle lines\n",
    "        for line in wrapped:\n",
    "            logger.info(f\"{line_style} {line.ljust(box_width - 4)} {line_style}\")\n",
    "\n",
    "        # Bottom border\n",
    "        logger.info(line_style * box_width)\n",
    "\n",
    "   \n",
    "    @staticmethod\n",
    "    def correl_table(params):\n",
    "        \"\"\"Return a printable correlation table for a Parameters object.\"\"\"\n",
    "        varnames = [vname for vname in params if params[vname].vary]\n",
    "        nwid = max(8, max([len(vname) for vname in varnames])) + 1\n",
    "\n",
    "        def sfmt(a):\n",
    "            return f\" {a:{nwid}s}\"\n",
    "\n",
    "        def ffmt(a):\n",
    "            return sfmt(f\"{a:+.4f}\")\n",
    "\n",
    "        title = ['', sfmt('Variable')]\n",
    "        title.extend([sfmt(vname) for vname in varnames])\n",
    "\n",
    "        title = '|'.join(title) + '|'\n",
    "        bar = [''] + ['-'*(nwid+1) for i in range(len(varnames)+1)] + ['']\n",
    "        bar = '+'.join(bar)\n",
    "\n",
    "        buff = [bar, title, bar]\n",
    "\n",
    "        for vname, par in params.items():\n",
    "            if not par.vary:\n",
    "                continue\n",
    "            line = ['', sfmt(vname)]\n",
    "            for vother in varnames:\n",
    "                if vother == vname:\n",
    "                    line.append(ffmt(1))\n",
    "                elif vother in par.correl:\n",
    "                    line.append(ffmt(par.correl[vother]))\n",
    "                else:\n",
    "                    line.append('unknown')\n",
    "            buff.append('|'.join(line) + '|')\n",
    "        buff.append(bar)\n",
    "        return '\\n'.join(buff)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def lmfit_report(\n",
    "            inpars, \n",
    "            r2_dict=None,\n",
    "            modelpars=None, \n",
    "            show_correl=True, \n",
    "            min_correl=0.1,\n",
    "            sort_pars=False, \n",
    "            correl_mode='list'\n",
    "            ):\n",
    "        \"\"\"Generate a report of the fitting results.\n",
    "\n",
    "        The report contains the best-fit values for the parameters and their\n",
    "        uncertainties and correlations.\n",
    "\n",
    "        Args:\n",
    "            inpars (lmfit.Parameters): Input Parameters from fit or MinimizerResult returned from a fit.\n",
    "            r2_dict (dict, optional): Dictionary of calculated coefficient of determinations.\n",
    "            modelpars (lmfit.Parameters, optional): Known Model Parameters.\n",
    "            show_correl (bool, optional): Whether to show list of sorted correlations (default is True).\n",
    "            min_correl (float, optional): Smallest correlation in absolute value to show (default is 0.1).\n",
    "            sort_pars (bool or callable, optional): Whether to show parameter names sorted in alphanumerical order. \n",
    "                If False (default), then the parameters will be listed in the order they were added to the Parameters \n",
    "                dictionary. If callable, then this (one argument) function is used to extract a comparison key from each list element.\n",
    "            correl_mode ({'list', table'} str, optional): Mode for how to show correlations. Can be either 'list' (default) to show a \n",
    "                sorted (if ``sort_pars`` is True) list of correlation values, or 'table' to show a complete, formatted table of correlations.\n",
    "\n",
    "        Returns:\n",
    "            str: Multi-line text of fit report.\n",
    "        \"\"\"\n",
    "        def correl_table(params):\n",
    "            \"\"\"Return a printable correlation table for a Parameters object.\"\"\"\n",
    "            varnames = [vname for vname in params if params[vname].vary]\n",
    "            nwid = max(8, max([len(vname) for vname in varnames])) + 1\n",
    "\n",
    "            def sfmt(a):\n",
    "                return f\" {a:{nwid}s}\"\n",
    "\n",
    "            def ffmt(a):\n",
    "                return sfmt(f\"{a:+.4f}\")\n",
    "\n",
    "            title = ['', sfmt('Variable')]\n",
    "            title.extend([sfmt(vname) for vname in varnames])\n",
    "\n",
    "            title = '|'.join(title) + '|'\n",
    "            bar = [''] + ['-'*(nwid+1) for i in range(len(varnames)+1)] + ['']\n",
    "            bar = '+'.join(bar)\n",
    "\n",
    "            buff = [bar, title, bar]\n",
    "\n",
    "            for vname, par in params.items():\n",
    "                if not par.vary:\n",
    "                    continue\n",
    "                line = ['', sfmt(vname)]\n",
    "                for vother in varnames:\n",
    "                    if vother == vname:\n",
    "                        line.append(ffmt(1))\n",
    "                    elif vother in par.correl:\n",
    "                        line.append(ffmt(par.correl[vother]))\n",
    "                    else:\n",
    "                        line.append('unknown')\n",
    "                buff.append('|'.join(line) + '|')\n",
    "            buff.append(bar)\n",
    "            return '\\n'.join(buff)\n",
    "    \n",
    "        inpars = copy.deepcopy(inpars) # MAKE OWN COPY\n",
    "        \n",
    "        if isinstance(inpars, lmfit.Parameters):\n",
    "            result, params = None, inpars\n",
    "        if hasattr(inpars, 'params'):\n",
    "            result = inpars\n",
    "            params = inpars.params\n",
    "\n",
    "\n",
    "        if sort_pars:\n",
    "            if callable(sort_pars):\n",
    "                key = sort_pars\n",
    "            else:\n",
    "                key = alphanumeric_sort\n",
    "            parnames = sorted(params, key=key)\n",
    "        else:\n",
    "            # dict.keys() returns a KeysView in py3, and they're indexed\n",
    "            # further down\n",
    "            parnames = list(params.keys())\n",
    "\n",
    "        if r2_dict is None:\n",
    "            r2_dict = {}\n",
    "\n",
    "        buff = []\n",
    "        add = buff.append\n",
    "        namelen = max(len(n) for n in parnames)\n",
    "        if result is not None:\n",
    "            add(\"[[Fit Statistics]]\")\n",
    "            add(f\"    # fitting method   = {result.method}\")\n",
    "            add(f\"    # function evals   = {getfloat_attr(result, 'nfev')}\")\n",
    "            add(f\"    # data points      = {getfloat_attr(result, 'ndata')}\")\n",
    "            add(f\"    # variables        = {getfloat_attr(result, 'nvarys')}\")\n",
    "            add(f\"    chi-square         = {getfloat_attr(result, 'chisqr')}\")\n",
    "            add(f\"    reduced chi-square = {getfloat_attr(result, 'redchi')}\")\n",
    "            add(f\"    Akaike info crit   = {getfloat_attr(result, 'aic')}\")\n",
    "            add(f\"    Bayesian info crit = {getfloat_attr(result, 'bic')}\")\n",
    "            if hasattr(result, 'rsquared'):\n",
    "                add(f\"    R-squared          = {getfloat_attr(result, 'rsquared')}\")\n",
    "            else:  ## ADD THIS PART\n",
    "                mean_val = r2_dict.get('mean', None)\n",
    "                weighted_val = r2_dict.get('weighted', None)\n",
    "                # Only proceed if at least one value is not None\n",
    "                if mean_val is not None and weighted_val is not None:\n",
    "                    tol = 1e-12\n",
    "                    if abs(mean_val - weighted_val) < tol:\n",
    "                        add(f\"    R-squared          = {getfloat_key(r2_dict, 'mean')}\")\n",
    "                    else:\n",
    "                        add(f\"    R-squared (mean)   = {getfloat_key(r2_dict, 'mean')}\")\n",
    "                        add(f\"    R-squared (weight) = {getfloat_key(r2_dict, 'weighted')}\")\n",
    "                elif mean_val is not None:\n",
    "                    add(f\"    R-squared (mean)   = {getfloat_key(r2_dict, 'mean')}\")\n",
    "                elif weighted_val is not None:\n",
    "                    # add(f\"    R-squared (weighted) = {getfloat_key(r2_dict, 'weighted')}\")\n",
    "                    # add(f\"    R-squared (var)    = {getfloat_key(r2_dict, 'weighted')}\")\n",
    "                    add(f\"    R-squared (weight) = {getfloat_key(r2_dict, 'weighted')}\")\n",
    "                # else: both None → do nothing (no add)\n",
    "                \n",
    "            if not result.errorbars:\n",
    "                add(\"##  Warning: uncertainties could not be estimated:\")\n",
    "                if result.method in ('leastsq', 'least_squares') or HAS_NUMDIFFTOOLS:\n",
    "                    parnames_varying = [par for par in result.params\n",
    "                                        if result.params[par].vary]\n",
    "                    for name in parnames_varying:\n",
    "                        par = params[name]\n",
    "                        space = ' '*(namelen-len(name))\n",
    "                        if par.init_value and np.allclose(par.value, par.init_value):\n",
    "                            add(f'    {name}:{space}  at initial value')\n",
    "                        if (np.allclose(par.value, par.min) or np.allclose(par.value, par.max)):\n",
    "                            add(f'    {name}:{space}  at boundary')\n",
    "                else:\n",
    "                    add(\"    this fitting method does not natively calculate uncertainties\")\n",
    "                    add(\"    and numdifftools is not installed for lmfit to do this. Use\")\n",
    "                    add(\"    `pip install numdifftools` for lmfit to estimate uncertainties\")\n",
    "                    add(\"    with this fitting method.\")\n",
    "\n",
    "        add(\"[[Variables]]\")\n",
    "        for name in parnames:\n",
    "            par = params[name]\n",
    "            space = ' '*(namelen-len(name))\n",
    "            nout = f\"{name}:{space}\"\n",
    "            inval = '(init = ?)'\n",
    "            if par.init_value is not None:\n",
    "                inval = f'(init = {par.init_value:.7g})'\n",
    "            if modelpars is not None and name in modelpars:\n",
    "                inval = f'{inval}, model_value = {modelpars[name].value:.7g}'\n",
    "            try:\n",
    "                sval = gformat(par.value)\n",
    "            except (TypeError, ValueError):\n",
    "                sval = ' Non Numeric Value?'\n",
    "            if par.stderr is not None:\n",
    "                serr = gformat(par.stderr)\n",
    "                try:\n",
    "                    spercent = f'({abs(par.stderr/par.value):.2%})'\n",
    "                except ZeroDivisionError:\n",
    "                    spercent = ''\n",
    "                sval = f'{sval} +/-{serr} {spercent}'\n",
    "\n",
    "            if par.vary:\n",
    "                add(f\"    {nout} {sval} {inval}\")\n",
    "            elif par.expr is not None:\n",
    "                add(f\"    {nout} {sval} == '{par.expr}'\")\n",
    "            else:\n",
    "                add(f\"    {nout} {par.value: .7g} (fixed)\")\n",
    "\n",
    "        if show_correl and correl_mode.startswith('tab'):\n",
    "            add('[[Correlations]] ')\n",
    "            for line in correl_table(params).split('\\n'):\n",
    "                buff.append('  %s' % line)\n",
    "        elif show_correl:\n",
    "            correls = {}\n",
    "            for i, name in enumerate(parnames):\n",
    "                par = params[name]\n",
    "                if not par.vary:\n",
    "                    continue\n",
    "                if hasattr(par, 'correl') and par.correl is not None:\n",
    "                    for name2 in parnames[i+1:]:\n",
    "                        if (name != name2 and name2 in par.correl and\n",
    "                                abs(par.correl[name2]) > min_correl):\n",
    "                            correls[f\"{name}, {name2}\"] = par.correl[name2]\n",
    "\n",
    "            sort_correl = sorted(correls.items(), key=lambda it: abs(it[1]))\n",
    "            sort_correl.reverse()\n",
    "            if len(sort_correl) > 0:\n",
    "                add('[[Correlations]] (unreported correlations are < '\n",
    "                    f'{min_correl:.3f})')\n",
    "                maxlen = max(len(k) for k in list(correls.keys()))\n",
    "            for name, val in sort_correl:\n",
    "                lspace = max(0, maxlen - len(name))\n",
    "                add(f\"    C({name}){(' '*30)[:lspace]} = {val:+.4f}\")\n",
    "        return '\\n'.join(buff)\n",
    "    \n",
    " \n",
    "    @staticmethod\n",
    "    def wrap_model_reprstring(expr, width=80, indent=4):\n",
    "        \"\"\"Wrap a composite model expression string at operators for readability.\n",
    "\n",
    "        Args:\n",
    "            expr (str): The composite model expression string.\n",
    "            width (int, optional): Max line width (default is 80).\n",
    "            indent (int, optional): Spaces to indent continuation lines (default is 4)\n",
    "\n",
    "        Returns:\n",
    "            str: Wrapped expression string.\n",
    "        \"\"\"\n",
    "        tokens = re.split(r'(\\+|\\-|\\*|/)', expr)  # split but keep operators\n",
    "        lines = []\n",
    "        current = \"\"\n",
    "\n",
    "        for tok in tokens:\n",
    "            if len(current) + len(tok) + 1 > width:\n",
    "                lines.append(current.rstrip())\n",
    "                current = \" \" * indent + tok\n",
    "            else:\n",
    "                current += tok\n",
    "        if current:\n",
    "            lines.append(current.rstrip())\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, items, independent_vars=None, nan_policy='raise', method='leastsq', **fit_kws):\n",
    "        \"\"\"\n",
    "        Create lmfit-global function from user-supplied model function.\n",
    "\n",
    "        Args:\n",
    "            items (dict) : Dictionary defining the model problem. Here is the how it is define\n",
    "                - 'data' : dict\n",
    "                    Defines the experimental data to be fitted, formatted as, \n",
    "                        {'xy': np.column_stack([x, y_1, y_2, ...]), 'xrange': None}\n",
    "\n",
    "                    * 'xy' a 2-D array with columns [x, y_1, y_2, ...].\n",
    "                    * 'xrange' can specify a domain restriction (or None) for fitting range [NOT SURE HERE].\n",
    "\n",
    "                - 'functions' : dict\n",
    "                    Defines the theoretical model functions and how they are combined.\n",
    "                    Must contain:\n",
    "                        'theory' : list of dicts\n",
    "                            Each dict specifies one function with:\n",
    "                                - 'func_name' : callable\n",
    "                                    The model function (e.g., gaussian, exponential).\n",
    "                                - 'init_params' : dict\n",
    "                                    Initial parameter guesses. Each parameter is itself\n",
    "                                    a dict with keys like 'value', 'vary', 'min', 'max'.\n",
    "                                - 'fixed_opts' : dict\n",
    "                                    Non-fit options (e.g., constants).\n",
    "                                - 'func_kws' : dict \n",
    "                                    Additional keyword arguments to pass to model function `'func_name'`.\n",
    "                                    Default to {}\n",
    "\n",
    "                        'theory_connectors' : list of str\n",
    "                            Binary operators ('+', '-', '*', '/') defining how to\n",
    "                            combine the functions in 'theory'. Length must be one less\n",
    "                            than the number of theory functions. For example:\n",
    "                                ['+', '*'] means theory[0] + theory[1] * theory[2].\n",
    "\n",
    "            independent_vars (:obj:`list` of :obj:`str`, optional) :  Explicit names of independent variables \n",
    "                for the model `function` (default is None).\n",
    "            nan_policy ({'raise', 'propagate', 'omit'}, optional) : How to handle NaN or missing values in the data.\n",
    "                - `'raise'` : raise a `ValueError` (default)\n",
    "                - `'propagate'` : do nothing\n",
    "                - `'omit'` : drop missing data\n",
    "            method (str, optional) : Fitting method available in lmfit (default is 'leastsq')\n",
    "            prefix (str, optional) : Prefix used for the model. Default will be created with index [NOT SURE NEEDED].\n",
    "            **fit_kws (dict, optional) : Additional options to pass to the minimizer being used..\n",
    "\n",
    "        Notes:\n",
    "        - \n",
    "        - \n",
    "        - \n",
    "        \"\"\"\n",
    "        # --- Make own copy to avoid overwriting of internal elements ---\n",
    "        items = copy.deepcopy(items)\n",
    "        # for key, val in kws.items():\n",
    "        #     setattr(self, key, val)\n",
    " \n",
    "        self.items = items\n",
    "        self.method = method\n",
    "        self.fit_kws = fit_kws\n",
    "        self.nan_policy = nan_policy\n",
    "        self.independent_vars = independent_vars\n",
    "\n",
    "        # --- Define Data attributes ---\n",
    "        self.data_x, self.data_y = None, None\n",
    "        self.xdat, self.ydat = None, None\n",
    "        self.data_xrange = None \n",
    "        self.has_nan = False\n",
    "\n",
    "        # --- Define Function attributes ---\n",
    "        self.nc = None\n",
    "        self._prefix_on = False\n",
    "        self.theory_connectors = None\n",
    "        \n",
    "        # --- Validate inputs ---\n",
    "        self._validate_data()\n",
    "        self._validate_functions()\n",
    "        self._validate_nan_policy()\n",
    "\n",
    "\n",
    "        # --- Containers to build model ---\n",
    "        self.models = []\n",
    "        self.prefixes = []\n",
    "        self.func_kws_all = []   # list of dict: Additional keyword arguments to pass to model function (IF ANY).\n",
    "        self.functions_used = []\n",
    "        self.function_names = []\n",
    "        self.composite_model = []\n",
    "        # self.fixed_options_all = [] # REMOVED (replaced with self.kws_all)\n",
    "        self.independent_vars_all = []\n",
    "        \n",
    "\n",
    "        # --- Build initial parameters ---\n",
    "        self.initial_params = lmfit.Parameters()\n",
    "\n",
    "\n",
    "        # --- Initiate fitting program ---\n",
    "        self.rss = []\n",
    "        self.r2 = {}\n",
    "        self.r2_dict = {}\n",
    "        self.r2_raw = None\n",
    "        self.r2_mean = None\n",
    "        self.r2_weighted = None\n",
    "        self.fit_success = False\n",
    "        # self._eval()\n",
    "        # logger.info(f'Evaluating lmfit fitting/minimization protocols for the functions...')\n",
    "        # logger.info(f'Setting lmfit fitting/minimization protocols for the functions...')\n",
    "\n",
    "        # --- setup: create model and initialize parameters ---\n",
    "        self.setup()\n",
    "        \n",
    "        # --- print model functions expressions ---\n",
    "        self.funcs_expr = self.build_expression(funcs=self.functions_used, operators=self.theory_connectors)\n",
    "        self.funcs_expr = f'y(x;) = {self.funcs_expr}'\n",
    "        self.pretty_expr(self.funcs_expr, line_style='#', width=80)  # LOGGER VERSION\n",
    "        # print_in_box(self.funcs_expr, line_style='#', width=80)      # PRINT VERSION\n",
    "\n",
    "\n",
    "\n",
    "    def setup(self):\n",
    "        \"\"\"Prepare models and initialize parameters for fitting.\"\"\"\n",
    "        self._create_models()\n",
    "        self._initialize_parameters()\n",
    "        self._build_composite_model()\n",
    "        self._eval()\n",
    "        # self._eval_init()\n",
    "        # logger.info(f'Evaluating lmfit fitting/minimization protocols for the functions...')\n",
    "        logger.info(f'Setting lmfit fitting/minimization protocols for the functions...')\n",
    "\n",
    "    # -------------------------------\n",
    "    # Properties\n",
    "    # -------------------------------\n",
    "    @property\n",
    "    def prefix_on(self):\n",
    "        return self._prefix_on\n",
    "\n",
    "    @prefix_on.setter\n",
    "    def prefix_on(self, value):\n",
    "        if not isinstance(value, bool):\n",
    "            raise TypeError(\"prefix_on must be a boolean\")\n",
    "        self._prefix_on = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f'LmfitGlobal(N={self.N}, ny={self.ny}, nc={self.nc}, '\n",
    "            f'nan_policy=\"{self.nan_policy}\", prefix_on={self._prefix_on}, '\n",
    "            f'expr=\"{self.funcs_expr}\") '\n",
    "            )\n",
    "    \n",
    "    \n",
    "    # -------------------------------\n",
    "    # Validation helpers\n",
    "    # -------------------------------\n",
    "    def _validate_data(self):\n",
    "        \"\"\"Extract and validate data info.\"\"\"\n",
    "        data_dict = self.items.get('data', None)\n",
    "        if data_dict is None:\n",
    "            msg=f'Raw data needed for fit'\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.data_dict = data_dict\n",
    "        self.data_xy = self.data_dict.get('xy', None)\n",
    "        if self.data_xy is None:\n",
    "            msg=f'Raw x-y data needed for fit'\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        arr = np.asarray(self.data_xy)\n",
    "        if arr.ndim != 2:\n",
    "            msg=f'We expect x-y data to be a 2D array'\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.data_x = arr[:, 0]\n",
    "        self.data_y = arr[:, 1:]\n",
    "        # --- extract number of dataset ny and length N of each dataset\n",
    "        self.N, self.ny = self.data_y.shape\n",
    "\n",
    "        # ---- Fit range [NOT SURE II SHOULD COME HERE! PERHAPS IN FUNCTION] ----\n",
    "        self.data_xrange = self.data_dict.get('xrange', None)\n",
    "        self.xdat, self.ydat = self.data_x, self.data_y\n",
    "\n",
    "        # if self.data_xrange:\n",
    "        #     if not isinstance(self.data_xrange, (list, tuple)) or len(self.data_xrange) != 2:\n",
    "        #         raise ValueError(\"`data_xrange` must be a list/tuple of two numbers\")\n",
    "        #     minval, maxval = self.data_xrange\n",
    "        #     idx = np.where((self.data_x >= minval) & (self.data_x <= maxval))[0]\n",
    "        #     self.xdat = np.take(self.data_x, idx)\n",
    "        #     self.ydat = np.take(self.data_y, idx, axis=0)\n",
    "\n",
    "        if self.data_xrange is not None:\n",
    "            if not self.data_xrange:  # catches [], (), '', 0, False\n",
    "                msg=f'`data_xrange` cannot be empty'\n",
    "                logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "            if (\n",
    "                not isinstance(self.data_xrange, (list, tuple)) or len(self.data_xrange)!=2 or \n",
    "                not all(isinstance(xr, (int, float)) for xr in self.data_xrange)\n",
    "            ):\n",
    "                msg=f'`data_xrange` must be a list/tuple of two numbers, got: {self.data_xrange}'\n",
    "                logger.error(msg) \n",
    "                raise ValueError(msg) \n",
    "        if self.data_xrange:\n",
    "            minval, maxval = self.data_xrange\n",
    "            idx = np.where((self.data_x >= minval) & (self.data_x <= maxval))[0]\n",
    "            # ---- Safety check: ensure we found at least one index ---\n",
    "            if idx.size == 0:\n",
    "                msg = (\n",
    "                    f'No data points found in the specified range {self.data_xrange}. '\n",
    "                    'Please check your input range or data.'\n",
    "                )\n",
    "                logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "            # --- Apply the index selection\n",
    "            self.xdat = np.take(self.data_x, idx)          # the range data we are interested to fit\n",
    "            self.ydat = np.take(self.data_y, idx, axis=0)  # the range data we are interested to fit\n",
    "        logger.info(f'Validating data...')\n",
    "\n",
    "\n",
    "    def _validate_functions(self):\n",
    "        \"\"\"Extract and validate theory/functions info.\"\"\"\n",
    "        func_dict = self.items.get('functions', None)\n",
    "        if func_dict is None:\n",
    "            msg=f'Theory/Functions needed for fit'\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.func_dict = func_dict\n",
    "        self.theory_dict = self.func_dict.get('theory', None)\n",
    "        if self.theory_dict is None:\n",
    "            msg=f'Fit Functions (`theory`) are required for fitting'\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.nc = len(self.theory_dict)\n",
    "        self.theory_connectors = self.func_dict.get('theory_connectors', None)\n",
    "\n",
    "        if self.nc > 1:\n",
    "            self._prefix_on = True\n",
    "            if self.theory_connectors is None:\n",
    "                msg=f'Missing `theory_connectors` list — required for multiple theory functions'\n",
    "                logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "            if not isinstance(self.theory_connectors, list):\n",
    "                msg=f'`theory_connectors` must be a list'\n",
    "                logger.error(msg)\n",
    "                raise TypeError(msg)\n",
    "            if not all(isinstance(op, str) and op in self._valid_connectors for op in self.theory_connectors):\n",
    "                msg=f'`theory_connectors` must contain only {self._valid_connectors}'\n",
    "                logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "            if len(self.theory_connectors) != self.nc - 1:\n",
    "                msg=f'Expected {self.nc - 1} connectors for {self.nc} theory functions'\n",
    "                logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "            # Precompile operator functions\n",
    "            self.connectors = [self._valid_connectors_dict[op] for op in self.theory_connectors]\n",
    "        else:\n",
    "            self._prefix_on = False\n",
    "            msg=f'`theory_connectors` ignored - ONLY <{self.nc}> function provided.'\n",
    "            logger.warning(msg)\n",
    "            msg=f\"`theory_connectors` = <{self.theory_connectors}> was reset to []\"\n",
    "            logger.warning(msg)\n",
    "            self.theory_connectors = []\n",
    "            # if self.theory_connectors not in (None, [], ()):\n",
    "            #     raise ValueError('`theory_connectors` must be None or empty when only one theory function is provided')\n",
    "        logger.info(f'Validating functions...')\n",
    "            \n",
    "\n",
    "    def _validate_nan_policy(self):\n",
    "        \"\"\"Check NaN Policy and Handle accordingly\"\"\"\n",
    "        # -- Check of the the raw data to fit has NaNs\n",
    "        self.has_nan = np.isnan(self.ydat).any()\n",
    "        # -- Raise error if NaNs are found and policy is 'raise'\n",
    "        if self.has_nan and self.nan_policy == 'raise':\n",
    "            msg = (\n",
    "                'Detected NaN values in `ydat`, but `nan_policy=\"raise\"` is active.\\n'\n",
    "                'Please clean your data or choose a different `nan_policy`:\\n'\n",
    "                '  - \"omit\"      -> automatically exclude NaN-containing points from the fit\\n'\n",
    "                '  - \"propagate\" -> allow NaNs to pass through (may result in NaN outputs)\\n'\n",
    "                '  - \"raise\"     -> (default) stop and alert if any NaNs are present'\n",
    "            )\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "        logger.info(f'Validating nan policy...')\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # Creating Model(s) Functions\n",
    "    # -------------------------------\n",
    "    def _create_models(self):\n",
    "        \"\"\"\n",
    "        Create lmfit.Model objects for each theory entry.\n",
    "\n",
    "        Builds a list of models, their function names, prefixes, and independent\n",
    "        variables. Parameter hints are applied from `init_params`, and fixed options\n",
    "        `func_kws` are stored separately for later use.\n",
    "        \"\"\"\n",
    "        # # --- Reset containers to avoid stale state ---\n",
    "        # self.functions_used = []\n",
    "        # self.function_names = []\n",
    "        # self.prefixes = []\n",
    "        # self.independent_vars_all = []\n",
    "        # self.fixed_options_all = []\n",
    "        # self.models = []\n",
    "\n",
    "        for i, entry in enumerate(self.theory_dict):\n",
    "            func = entry.get('func_name', None)\n",
    "            if func is None or not callable(func):\n",
    "                msg=f'Missing or invalid `\"func_name\"` in theory_dict[{i}] — must be a callable.'\n",
    "                logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "            self.functions_used.append(func)\n",
    "            self.function_names.append(func.__name__)\n",
    "\n",
    "            init_params = entry.get('init_params', None)\n",
    "            if init_params is None:\n",
    "                msg=f'Missing `\"init_params\"` for function `{func.__name__}`'\n",
    "                logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "\n",
    "            if not isinstance(init_params, dict):\n",
    "                msg = f'`init_params` for function `{func.__name__}` must be a dict.'\n",
    "                logger.error(msg)\n",
    "                raise TypeError(msg)\n",
    "\n",
    "            # fixed_opts = entry.get('fixed_opts', {}) # REMOVED (replaced with func_kws)\n",
    "            func_kws = entry.get('func_kws', {})\n",
    "\n",
    "            # --- Get ordered function parameters ---\n",
    "            fn_pars = list(inspect.signature(func).parameters.keys())\n",
    "            xpar = fn_pars[:1]  # first argument is EXPECTED to 'x'\n",
    "             # --- Tell lmfit which arguments are independent variables like `fixed_opts` ---\n",
    "            # indep_vars = xpar + list(fixed_opts.keys()) # REMOVED (replaced with func_kws)\n",
    "            indep_vars = xpar + list(func_kws.keys())\n",
    "\n",
    "            # --- Warn if init_params contain unexpected arguments ---\n",
    "            unexpected = set(init_params.keys()) - set(fn_pars)\n",
    "            if unexpected:\n",
    "                # logger.warning(\n",
    "                #     f'Function `{func.__name__}`: \"init_params\" contain unexpected arguments {unexpected}. '\n",
    "                #     f'These are not in the function signature {fn_pars}.'\n",
    "                # )\n",
    "                msg = (\n",
    "                    f'Function `{func.__name__}`: \"init_params\" contain unexpected arguments {unexpected}.\\n'\n",
    "                    f'These are not in the function signature: {fn_pars}.'\n",
    "                )\n",
    "                logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "\n",
    "            # --- Check func_kws consistency ---\n",
    "            unexpected_kws = set(func_kws.keys()) - set(fn_pars)\n",
    "            if unexpected_kws:\n",
    "                msg = (\n",
    "                    f'Function `{func.__name__}`: \"func_kws\" contain unexpected keyword arguments {unexpected_kws}.\\n'\n",
    "                    f'These are not in the function signature: {fn_pars}.'\n",
    "                )\n",
    "                logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "\n",
    "            # --- Prefix for multi-component models ----\n",
    "            prefix = f'c{i}_' if self.prefix_on else f''\n",
    "            self.prefixes.append(prefix)\n",
    "\n",
    "            # --- Build lmfit.Model ---\n",
    "            # model = lmfit.Model(func, prefix=prefix)\n",
    "            model = lmfit.Model(func, independent_vars=indep_vars, prefix=prefix)\n",
    "            self.independent_vars_all.append(indep_vars)\n",
    "\n",
    "            # # --- Apply parameter hints for fit parameters ---\n",
    "            # for pname, hint in init_params.items():\n",
    "            #     model.set_param_hint(pname, **hint)\n",
    "\n",
    "            # --- Allowed keys for lmfit set_param_hint ---\n",
    "            valid_keys = {\"value\", \"vary\", \"min\", \"max\", \"expr\", \"brute_step\"}\n",
    "\n",
    "            # --- Apply parameter hints for fit parameters ---\n",
    "            for pname, hint in init_params.items():\n",
    "                if not isinstance(hint, dict):\n",
    "                    msg = f\"Parameter hint for '{pname}' must be a dict, got {type(hint)}\"\n",
    "                    logger.error(msg)\n",
    "                    raise TypeError(msg)\n",
    "\n",
    "                # Empty dict is fine (lmfit will use defaults)\n",
    "                if hint:\n",
    "                    unexpected_keys = set(hint.keys()) - valid_keys\n",
    "                    if unexpected_keys:\n",
    "                        msg = (\n",
    "                            f'Function `{func.__name__}`: parameter \"{pname}\" has invalid hint keys {unexpected_keys}.\\n'\n",
    "                            f'Allowed keys are: {sorted(valid_keys)}.'\n",
    "                            # f'Allowed keys are: {valid_keys}.'\n",
    "                        )\n",
    "                        logger.error(msg)\n",
    "                        raise ValueError(msg)\n",
    "\n",
    "                # Safe to apply\n",
    "                model.set_param_hint(pname, **hint)\n",
    "\n",
    "            # --- Store the fixed options so we can pass them later ---\n",
    "            model.func_kws = func_kws # NOT A GOOD IDEA\n",
    "            # Store fixed options separately\n",
    "            # self.fixed_options_all.append(fixed_opts) # REMOVED (replaced with self.func_kws_all)\n",
    "            self.func_kws_all.append(func_kws)\n",
    "            self.models.append(model)\n",
    "        logger.info(f'Creating lmfit.Models for the functions...')\n",
    "\n",
    "\n",
    "    def _initialize_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize lmfit.Parameters for all datasets and models.\n",
    "\n",
    "        Each dataset gets its own parameter set, with names suffixed by the dataset index.\n",
    "        \"\"\"\n",
    "        # # --- Rest parameter\n",
    "        # self.initial_params = lmfit.Parameters()\n",
    "\n",
    "        for iy in range(self.ny):  # loop over datasets\n",
    "            for model in self.models:  # loop over models\n",
    "                initpar = model.make_params()\n",
    "                for name, par_dict in initpar.items():\n",
    "                    pname = f\"{name}_{iy}\"  # dataset-specific suffix\n",
    "                    self.initial_params.add(\n",
    "                        pname,\n",
    "                        value=par_dict.value,\n",
    "                        vary=par_dict.vary,\n",
    "                        min=par_dict.min,\n",
    "                        max=par_dict.max,\n",
    "                    )\n",
    "        logger.info(f'Initializing lmfit.Parameters for the functions...')\n",
    "        # # --- print model functions expressions ---\n",
    "        # self.funcs_expr = self.build_expression(funcs=self.functions_used, operators=self.theory_connectors)\n",
    "        # self.funcs_expr = f'y(x;) = {self.funcs_expr}'\n",
    "        # print_in_box(self.funcs_expr, line_style='#', width=80)\n",
    "    \n",
    "\n",
    "    def _build_composite_model(self):\n",
    "        \"\"\"Build a composite similar to lmfit.CompositeModel from a list of models and operators\n",
    "        to connect the models in the list.\n",
    "        \"\"\"\n",
    "        models = self.models\n",
    "        operators = self.theory_connectors\n",
    "        operator_map = self._valid_connectors_dict\n",
    "\n",
    "        self.composite_model = self.reduce_with_operators(\n",
    "            items=models, \n",
    "            ops=operators, \n",
    "            operator_map=operator_map\n",
    "            )\n",
    "\n",
    "\n",
    "    def _evaluate_models(self, xdat, params, i):\n",
    "        \"\"\"Evaluate all models for a given dataset index `i` and combine them\n",
    "        using the theory connectors.\n",
    "\n",
    "        Args:\n",
    "            xdat (array, list of floats): Array-like of x data, xdat.\n",
    "            params (lmfit.Parameters): Parameter set containing values for all model components.\n",
    "            i (int): Dataset index specifying which column of y-data to evaluate.\n",
    "\n",
    "        Returns:\n",
    "        r (nd.array): The combined model output for the given dataset index,\n",
    "            constructed by applying the operators in `self.theory_connectors`\n",
    "            to the individual model results.\n",
    "        \"\"\"\n",
    "\n",
    "        results = []\n",
    "        models = self.models\n",
    "        operators = self.theory_connectors\n",
    "        operator_map = self._valid_connectors_dict\n",
    "        for midx, model in enumerate(models):\n",
    "            y = self.evaluate_function(\n",
    "                func=model.func,\n",
    "                x=xdat,\n",
    "                params=params,\n",
    "                # prefix=self.prefixes[midx],\n",
    "                prefix=model.prefix,       # cleaner\n",
    "                i=i,\n",
    "                # func_kws=self.func_kws_all[midx],\n",
    "                func_kws=model.func_kws,   # self-contained\n",
    "            )\n",
    "            results.append(y)\n",
    "\n",
    "        # Combine results using operators\n",
    "        r = self.reduce_with_operators(\n",
    "            items=results,\n",
    "            ops=operators, \n",
    "            operator_map=operator_map\n",
    "        )\n",
    "        return r\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Parameters Helpers\n",
    "    # -------------------------------\n",
    "    def _set_global_params(self, *parlist):\n",
    "        \"\"\"INTERNAL IMPLEMENTATIONS\n",
    "        Tie one or more parameters to a single master parameter, making them global (shared).\n",
    "\n",
    "        This method ties all indexed variants of a parameter (e.g. \"sigma_0\", \"sigma_1\", ...)\n",
    "        to a single master parameter. The master parameter retains its original `vary` flag\n",
    "        (free or fixed) as defined in `self.initial_params`. All dependent parameters are\n",
    "        set with `expr=master_name` so they share the master’s value.\n",
    "\n",
    "        Args:\n",
    "            *parlist (str | list[str] | lmfit.Parameter | lmfit.Parameters | sequence):\n",
    "                Parameter(s) to globalize. Supported forms include:\n",
    "                  - A single parameter name string (e.g. \"sigma_0\")\n",
    "                  - A list of parameter name strings\n",
    "                  - An `lmfit.Parameters` object (all keys will be globalized)\n",
    "                  - A sequence of `(name, Parameter)` tuples (e.g. `params.items()`)\n",
    "                  - A sequence of `Parameter` instances\n",
    "                  - Multiple arguments (e.g. `_set_global_params(p1, p2, \"sigma_0\")`)\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If a supplied parameter name or master parameter is not found\n",
    "                        in `self.initial_params`.\n",
    "            TypeError: If `parlist` contains unsupported types.\n",
    "\n",
    "        Notes:\n",
    "            - The master parameter's `expr` is cleared to ensure independence.\n",
    "            - The maste's `vary` flag is restored to its original state after tying.\n",
    "            - If the master is fixed (`vary=False`), all tied parameters will also be fixed.\n",
    "            - Logging is used to inform about globalizing actions and warnings.\n",
    "\n",
    "        Examples:\n",
    "            >>> # Example 1: single string\n",
    "            >>> LmfitGlobal._set_global_params(\"sigma_0\")\n",
    "\n",
    "            >>> # Example 2: list of strings\n",
    "            >>> LmfitGlobal._set_global_params([\"center_1\"])   # list of str\n",
    "            >>> LmfitGlobal._set_global_params([\"center_1\", \"amplitude_0\"])  # list of str\n",
    "        \n",
    "            >>> # Example 3: lmfit.Parameter object\n",
    "            >>> from lmfit import Parameter\n",
    "            >>> par1 = Parameter(\"sigma_0\", 0.25)   # single par\n",
    "            >>> LmfitGlobal._set_global_params(par1)\n",
    "            >>> par1 = Parameter(\"sigma_0\", 0.25)   # single par\n",
    "            >>> par2 = Parameter(\"center_0\", 0.25)  # single par\n",
    "            >>> LmfitGlobal._set_global_params(par1, par2)\n",
    "\n",
    "            >>> # Example 4: lmfit.Parameters object\n",
    "            >>> from lmfit import Parameters\n",
    "            >>> params = Parameters()\n",
    "            >>> params.add(\"sigma_0\", value=0.25, vary=True)\n",
    "            >>> params.add(\"sigma_1\", value=0.25, vary=False)\n",
    "            >>> LmfitGlobal._set_global_params(params)\n",
    "\n",
    "            >>> # Example 5: sequence of Parameter instances\n",
    "            >>> from lmfit import Parameter\n",
    "            >>> p1 = Parameter(\"sigma_0\", value=0.25, vary=True)\n",
    "            >>> p2 = Parameter(\"sigma_1\", value=0.25, vary=False)\n",
    "            >>> LmfitGlobal._set_global_params([p1, p2])\n",
    "\n",
    "            >>> # Example 6: sequence of (name, Parameter) tuples\n",
    "            >>> LmfitGlobal._set_global_params(list(params.keys()))\n",
    "        \"\"\"\n",
    "        # # --- normalize input into names ---\n",
    "        # names = []\n",
    "        # for par in parlist:\n",
    "        #     if isinstance(par, str):\n",
    "        #         names.append(par)\n",
    "        #     elif isinstance(par, lmfit.Parameters):\n",
    "        #         names.extend(list(par.keys()))\n",
    "        #     elif isinstance(par, lmfit.Parameter):\n",
    "        #         names.append(par.name)\n",
    "        #     elif isinstance(par, (list, tuple)):\n",
    "        #         for item in par:\n",
    "        #             if isinstance(item, str):\n",
    "        #                 names.append(item)\n",
    "        #             elif isinstance(item, tuple) and len(item) == 2 and isinstance(item[1], lmfit.Parameter):\n",
    "        #                 names.append(item[0])\n",
    "        #             elif isinstance(item, lmfit.Parameter):\n",
    "        #                 names.append(item.name)\n",
    "        #             else:\n",
    "        #                 msg = f'Unsupported item type in parlist: {type(item)}'\n",
    "        #                 logger.error(msg)\n",
    "        #                 raise TypeError(msg)\n",
    "        #     else:\n",
    "        #         msg = f'Unsupported parlist type: {type(par)}'\n",
    "        #         logger.error(msg)\n",
    "        #         raise TypeError(msg)\n",
    "        \n",
    "        # --- normalize input into names ---\n",
    "        names = []\n",
    "        for par in parlist:\n",
    "            if isinstance(par, str):\n",
    "                names.append(par)\n",
    "            elif isinstance(par, lmfit.Parameters):\n",
    "                names.extend(list(par.keys()))\n",
    "            elif isinstance(par, lmfit.Parameter):\n",
    "                names.append(par.name)\n",
    "            elif isinstance(par, tuple) and len(par) == 2 and isinstance(par[1], lmfit.Parameter):\n",
    "                names.append(par[0])\n",
    "            elif isinstance(par, (list, tuple)):\n",
    "                for item in par:\n",
    "                    if isinstance(item, str):\n",
    "                        names.append(item)\n",
    "                    elif isinstance(item, tuple) and len(item) == 2 and isinstance(item[1], lmfit.Parameter):\n",
    "                        names.append(item[0])\n",
    "                    elif isinstance(item, lmfit.Parameter):\n",
    "                        names.append(item.name)\n",
    "                    else:\n",
    "                        msg = f'Unsupported item type in parlist: {type(item)}'\n",
    "                        logger.error(msg)\n",
    "                        raise TypeError(msg)\n",
    "            else:\n",
    "                msg = f'Unsupported parlist type: {type(par)}'\n",
    "                logger.error(msg)\n",
    "                raise TypeError(msg)\n",
    "\n",
    "        # deduplicate\n",
    "        names = list(dict.fromkeys(names))\n",
    "\n",
    "        # --- process normalized names ---\n",
    "        for param_name in names:\n",
    "            if param_name not in self.initial_params and \"_\" not in param_name:\n",
    "                msg = f'The parameter \"{param_name}\" not found in \"self.initial_params\"...'\n",
    "                logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "\n",
    "            # parse prefix and index\n",
    "            if '_' in param_name:\n",
    "                parname, idx = param_name.rsplit('_', 1)\n",
    "                idx = int(idx)\n",
    "            else:\n",
    "                parname, idx = param_name, 0\n",
    "\n",
    "            master_name = f'{parname}_{idx}'\n",
    "            if master_name not in self.initial_params:\n",
    "                msg = f'The parameter \"{master_name}\" not found in \"self.initial_params\"...'\n",
    "                logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "\n",
    "            # ensure master is independent\n",
    "            self.initial_params[master_name].expr = None\n",
    "            flag = self.initial_params[master_name].vary\n",
    "\n",
    "            logger.info(f'The parameter \"{master_name}\" is shared with ALL \"{parname}_*\" parameters...')\n",
    "\n",
    "            # tie all other indices to master\n",
    "            indices = sorted(set(range(self.ny)) - {idx})\n",
    "            for i in indices:\n",
    "                pname = f\"{parname}_{i}\"\n",
    "                if pname in self.initial_params:\n",
    "                    self.initial_params[pname].expr = master_name\n",
    "\n",
    "            # restore master’s vary flag\n",
    "            self.initial_params[master_name].set(vary=flag)\n",
    "\n",
    "            if not flag:\n",
    "                logger.warning(\n",
    "                    f'The parameter \"{master_name}\" is fixed (vary=False)... '\n",
    "                    'ALL shared parameters will also be fixed...'\n",
    "                )\n",
    "\n",
    "\n",
    "    def _set_global_params_group(self, *parlist):\n",
    "        \"\"\"\n",
    "        Tie all parameters in `parlist` (names, Parameter objects, or Parameters container)\n",
    "        to a single master parameter (the first one).\n",
    "        \"\"\"\n",
    "        names = []\n",
    "\n",
    "        for par in parlist:\n",
    "            if isinstance(par, str):\n",
    "                names.append(par)\n",
    "            elif isinstance(par, lmfit.Parameter):\n",
    "                names.append(par.name)\n",
    "            elif isinstance(par, lmfit.Parameters):\n",
    "                names.extend(list(par.keys()))   # all keys from Parameters object\n",
    "            elif isinstance(par, (list, tuple)):\n",
    "                for item in par:\n",
    "                    if isinstance(item, str):\n",
    "                        names.append(item)\n",
    "                    elif isinstance(item, lmfit.Parameter):\n",
    "                        names.append(item.name)\n",
    "                    elif isinstance(item, tuple) and len(item) == 2 and isinstance(item[1], lmfit.Parameter):\n",
    "                        names.append(item[0])\n",
    "                    else:\n",
    "                        msg=f'Unsupported item type: {type(item)}'\n",
    "                        logger.error(msg)\n",
    "                        raise TypeError(msg)\n",
    "            else:\n",
    "                msg=f'Unsupported parlist type: {type(par)}'\n",
    "                logger.error(msg)\n",
    "                raise TypeError(msg)\n",
    "\n",
    "        if not names:\n",
    "            msg=f'No parameters provided'\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        # deduplicate\n",
    "        names = list(dict.fromkeys(names))\n",
    "        # pick master (first one)\n",
    "        master_name = names[0]\n",
    "        if master_name not in self.initial_params:\n",
    "            msg=f'Master parameter \"{master_name}\" not found'\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        # ensure master independent\n",
    "        self.initial_params[master_name].expr = None\n",
    "        flag = self.initial_params[master_name].vary\n",
    "\n",
    "        # # tie all others\n",
    "        # for pname in names[1:]:\n",
    "        #     if pname not in self.initial_params:\n",
    "        #         msg=f'Parameter \"{pname}\" not found'\n",
    "        #         logger.error(msg)\n",
    "        #         raise ValueError(msg)\n",
    "        #     self.initial_params[pname].expr = master_name\n",
    "\n",
    "        # # restore master vary flag\n",
    "        # self.initial_params[master_name].set(vary=flag)\n",
    "\n",
    "        if len(names) > 1:\n",
    "            # tie all others\n",
    "            for pname in names[1:]:\n",
    "                if pname not in self.initial_params:\n",
    "                    msg = f'Parameter \"{pname}\" not found'\n",
    "                    logger.error(msg)\n",
    "                    raise ValueError(msg)\n",
    "                self.initial_params[pname].expr = master_name\n",
    "\n",
    "            # restore master’s vary flag AFTER tying\n",
    "            self.initial_params[master_name].set(vary=flag)\n",
    "\n",
    "            if not flag:\n",
    "                logger.warning(\n",
    "                    f'The parameter \"{master_name}\" is fixed (vary=False)... '\n",
    "                    'ALL shared parameters will also be fixed...'\n",
    "                )\n",
    "        else:\n",
    "            # only one parameter, nothing to tie\n",
    "            self.initial_params[master_name].set(vary=flag)\n",
    "            logger.warning(f'Only one parameter \"{master_name}\" provided — no dependents to tie.')\n",
    "\n",
    "        logger.info(f'ALL parameters {names} are now globalized with master \"{master_name}\"...')\n",
    "\n",
    "\n",
    "    ### --- EXPERIMENTAL ---###\n",
    "    def _set_global_expr(self, *parlist, expr=None):\n",
    "        \"\"\"\n",
    "        Tie parameters to user-defined expressions, optionally updating other attributes.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        *parlist : sequence of str, lmfit.Parameter, lmfit.Parameters, tuple, dict, or list\n",
    "            Supported forms:\n",
    "            - String: \"sigma_0\" (expr=None, clears expression unless overridden by keyword)\n",
    "            - lmfit.Parameter: uses its .expr and other attributes if defined\n",
    "            - lmfit.Parameters: all keys included, with their attributes\n",
    "            - Tuple: (\"sigma_0\", \"0.12 * sigma_1\") or (\"sigma_0\", Parameter)\n",
    "            - Dict: {\"name\": \"sigma_0\", \"expr\": \"0.12 * sigma_1\", \"value\": 0.25}\n",
    "            - Dict-of-dicts: {\"sigma_0\": {\"expr\": \"0.12 * sigma_1\"}, \"center_2\": {\"expr\": \"0.24 - sigma_0\"}}\n",
    "            - List/tuple of any of the above\n",
    "\n",
    "        expr : str, dict, or list of str, optional\n",
    "            If provided:\n",
    "            - str: overrides the expression for all names in *parlist\n",
    "            - dict: mapping of {name: expr} to override selectively\n",
    "            - list of str: must match len(*parlist); assigns expressions in order\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If a parameter name is not found in self.initial_params, or if expr list length mismatch.\n",
    "        TypeError\n",
    "            If unsupported input types are provided.\n",
    "        \"\"\"\n",
    "        valid_keys = {\"value\", \"vary\", \"min\", \"max\", \"expr\", \"brute_step\"}\n",
    "        updates_map = {}\n",
    "\n",
    "        # --- normalize parlist into updates_map[name] = {attributes} ---\n",
    "        for par in parlist:\n",
    "            if isinstance(par, str):\n",
    "                updates_map[par] = {\"expr\": None}\n",
    "\n",
    "            elif isinstance(par, lmfit.Parameter):\n",
    "                updates = {}\n",
    "                for k in valid_keys:\n",
    "                    val = getattr(par, k, None)\n",
    "                    if val is not None:\n",
    "                        if k == \"min\" and val == -np.inf:\n",
    "                            continue\n",
    "                        if k == \"max\" and val == np.inf:\n",
    "                            continue\n",
    "                        updates[k] = val\n",
    "                updates_map[par.name] = updates\n",
    "\n",
    "            elif isinstance(par, lmfit.Parameters):\n",
    "                for name, p in par.items():\n",
    "                    updates = {}\n",
    "                    for k in valid_keys:\n",
    "                        val = getattr(p, k, None)\n",
    "                        if val is not None:\n",
    "                            if k == \"min\" and val == -np.inf:\n",
    "                                continue\n",
    "                            if k == \"max\" and val == np.inf:\n",
    "                                continue\n",
    "                            updates[k] = val\n",
    "                    updates_map[name] = updates\n",
    "\n",
    "            elif isinstance(par, dict):\n",
    "                if all(isinstance(v, dict) for v in par.values()):\n",
    "                    for name, attrs in par.items():\n",
    "                        updates = {k: v for k, v in attrs.items()\n",
    "                                if k in valid_keys and v is not None}\n",
    "                        updates_map[name] = updates\n",
    "                elif \"name\" in par:\n",
    "                    name = par[\"name\"]\n",
    "                    updates = {k: v for k, v in par.items()\n",
    "                            if k in valid_keys and v is not None}\n",
    "                    updates_map[name] = updates\n",
    "                else:\n",
    "                    raise TypeError(f'Dict must be either {{name, expr}} or dict-of-dicts, got {par}')\n",
    "\n",
    "            elif isinstance(par, tuple):\n",
    "                if len(par) == 2 and isinstance(par[1], lmfit.Parameter):\n",
    "                    updates_map[par[0]] = {\"expr\": par[1].expr}\n",
    "                elif len(par) == 2 and isinstance(par[1], str):\n",
    "                    updates_map[par[0]] = {\"expr\": par[1]}\n",
    "                else:\n",
    "                    raise TypeError(f'Unsupported tuple form: {par}')\n",
    "\n",
    "            elif isinstance(par, (list, tuple)):\n",
    "                for item in par:\n",
    "                    if isinstance(item, str):\n",
    "                        updates_map[item] = {\"expr\": None}\n",
    "                    elif isinstance(item, lmfit.Parameter):\n",
    "                        updates_map[item.name] = {\"expr\": item.expr}\n",
    "                    elif isinstance(item, tuple) and len(item) == 2 and isinstance(item[1], lmfit.Parameter):\n",
    "                        updates_map[item[0]] = {\"expr\": item[1].expr}\n",
    "                    elif isinstance(item, tuple) and len(item) == 2 and isinstance(item[1], str):\n",
    "                        updates_map[item[0]] = {\"expr\": item[1]}\n",
    "                    else:\n",
    "                        raise TypeError(f'Unsupported item type: {type(item)}')\n",
    "            else:\n",
    "                raise TypeError(f'Unsupported parlist type: {type(par)}')\n",
    "\n",
    "        if not updates_map:\n",
    "            raise ValueError('No parameters provided')\n",
    "\n",
    "        names = list(updates_map.keys())\n",
    "\n",
    "        # --- apply expr overrides ---\n",
    "        if expr is not None:\n",
    "            if isinstance(expr, str):\n",
    "                for name in names:\n",
    "                    updates_map[name][\"expr\"] = expr\n",
    "            elif isinstance(expr, dict):\n",
    "                for name, e in expr.items():\n",
    "                    if name in updates_map:\n",
    "                        updates_map[name][\"expr\"] = e\n",
    "            elif isinstance(expr, (list, tuple)):\n",
    "                if len(expr) != len(names):\n",
    "                    raise ValueError(\n",
    "                        f'expr list length {len(expr)} does not match number of parameters {len(names)}'\n",
    "                    )\n",
    "                for name, e in zip(names, expr):\n",
    "                    updates_map[name][\"expr\"] = e\n",
    "            else:\n",
    "                raise TypeError(\"expr must be str, dict, or list/tuple of str\")\n",
    "\n",
    "        # --- apply updates ---\n",
    "        for pname, updates in updates_map.items():\n",
    "            if pname not in self.initial_params:\n",
    "                raise ValueError(f'Parameter \"{pname}\" not found in initial_params')\n",
    "\n",
    "            if updates:\n",
    "                self.initial_params[pname].set(**updates)\n",
    "                if \"expr\" in updates and updates[\"expr\"] is None:\n",
    "                    logger.info(f'Cleared expr for \"{pname}\"')\n",
    "                elif \"expr\" in updates:\n",
    "                    logger.info(f'Set expr for \"{pname}\" → {updates[\"expr\"]}...')\n",
    "                else:\n",
    "                    logger.info(f'Updated \"{pname}\" with {updates}...')\n",
    "\n",
    "\n",
    "    ### --- EXPERIMENTAL (NEW) ---###\n",
    "    def _set_global_expr(self, *parlist, expr=None):\n",
    "        \"\"\"\n",
    "        Tie parameters in `parlist` to user-defined expressions.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        *parlist : sequence of str, lmfit.Parameter, lmfit.Parameters, tuple, or list\n",
    "            Supported forms:\n",
    "            - String: \"sigma_0\"\n",
    "            - lmfit.Parameter: uses its .name\n",
    "            - lmfit.Parameters: all keys included\n",
    "            - Tuple: (\"sigma_0\", Parameter)\n",
    "            - List/tuple of any of the above\n",
    "\n",
    "        expr : str, dict, or list of str, optional\n",
    "            If provided:\n",
    "            - str: same expression applied to all parameters\n",
    "            - dict: mapping of {name: expr} for selective assignment\n",
    "            - list of str: must match len(names); assigns expressions in order\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If no parameters provided, or if expr list length mismatch.\n",
    "        TypeError\n",
    "            If unsupported input types are provided.\n",
    "        \"\"\"\n",
    "        names = []\n",
    "\n",
    "        # --- normalize input into names ---\n",
    "        for par in parlist:\n",
    "            if isinstance(par, str):\n",
    "                names.append(par)\n",
    "            elif isinstance(par, lmfit.Parameter):\n",
    "                names.append(par.name)\n",
    "            elif isinstance(par, lmfit.Parameters):\n",
    "                names.extend(list(par.keys()))\n",
    "            elif isinstance(par, (list, tuple)):\n",
    "                for item in par:\n",
    "                    if isinstance(item, str):\n",
    "                        names.append(item)\n",
    "                    elif isinstance(item, lmfit.Parameter):\n",
    "                        names.append(item.name)\n",
    "                    elif isinstance(item, tuple) and len(item) == 2 and isinstance(item[1], lmfit.Parameter):\n",
    "                        names.append(item[0])\n",
    "                    else:\n",
    "                        msg = f'Unsupported item type: {type(item)}'\n",
    "                        logger.error(msg)\n",
    "                        raise TypeError(msg)\n",
    "            else:\n",
    "                msg = f'Unsupported parlist type: {type(par)}'\n",
    "                logger.error(msg)\n",
    "                raise TypeError(msg)\n",
    "\n",
    "        if not names:\n",
    "            msg = 'No parameters provided'\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        # deduplicate\n",
    "        names = list(dict.fromkeys(names))\n",
    "\n",
    "        # --- apply expr overrides ---\n",
    "        if expr is not None:\n",
    "            if isinstance(expr, str):\n",
    "                expr_map = {name: expr for name in names}\n",
    "            elif isinstance(expr, dict):\n",
    "                expr_map = {name: expr.get(name, None) for name in names}\n",
    "            elif isinstance(expr, (list, tuple)):\n",
    "                if len(expr) != len(names):\n",
    "                    raise ValueError(\n",
    "                        f'expr list length {len(expr)} does not match number of parameters {len(names)}'\n",
    "                    )\n",
    "                expr_map = dict(zip(names, expr))\n",
    "            else:\n",
    "                raise TypeError(\"expr must be str, dict, or list/tuple of str\")\n",
    "        else:\n",
    "            # default: clear exprs\n",
    "            expr_map = {name: None for name in names}\n",
    "\n",
    "        # --- apply to parameters ---\n",
    "        for pname, e in expr_map.items():\n",
    "            if pname not in self.initial_params:\n",
    "                msg = f'Parameter \"{pname}\" not found in initial_params'\n",
    "                logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "\n",
    "            self.initial_params[pname].expr = e\n",
    "            flag = self.initial_params[pname].vary\n",
    "            self.initial_params[pname].set(vary=flag)\n",
    "\n",
    "            if e is None:\n",
    "                logger.info(f'Cleared expr for \"{pname}\" (vary={flag})')\n",
    "            else:\n",
    "                logger.info(f'Set expr for \"{pname}\" → {e} (vary={flag})')\n",
    "\n",
    "\n",
    "    def set_global_params(self, *parlist):\n",
    "        \"\"\"\n",
    "        Public API: tie one or more parameters to a single master parameter.\n",
    "        This forwards to the internal `_set_global_params`.\n",
    "        \"\"\"\n",
    "        self._set_global_params(*parlist)\n",
    "\n",
    "    # optional alias\n",
    "    def set_global(self, *parlist):\n",
    "        \"\"\"Alias for set_global_params.\"\"\"\n",
    "        self._set_global_params(*parlist)\n",
    "\n",
    "\n",
    "    def set_global_params_group(self, *parlist):\n",
    "        \"\"\"\n",
    "        Public API: tie one or more parameters to a single master parameter.\n",
    "        This forwards to the internal `_set_global_params_group`.\n",
    "        \"\"\"\n",
    "        self._set_global_params_group(*parlist)\n",
    "\n",
    "    # optional alias\n",
    "    def set_global_group(self, *parlist):\n",
    "        \"\"\"Alias for set_global_params.\"\"\"\n",
    "        self._set_global_params_group(*parlist)\n",
    "\n",
    "    # optional alias\n",
    "    def set_global_expr(self, *parlist, expr=None):\n",
    "        \"\"\"Alias for _set_global_expr.\"\"\"\n",
    "        self._set_global_expr(*parlist, expr=expr)\n",
    "\n",
    "\n",
    "\n",
    "    ### --- EXPERIMENTAL ---###\n",
    "    def _update_params(self, *parlist):\n",
    "        \"\"\"\n",
    "        Update many parameters in `self.initial_params`.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        *parlist : sequence of tuple, dict, or Parameter\n",
    "            - Tuples: (name, value, vary, min, max, expr, brute_step)\n",
    "              Only provided elements are updated.\n",
    "            - Dicts: {'name': 'sigma', 'value': 0.25, 'vary': True}\n",
    "              Keys map directly to Parameter attributes.\n",
    "            - Parameter instances: update using their defined attributes.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - Existing parameters are updated in place.\n",
    "        - Only explicitly provided attributes are updated; others remain unchanged.\n",
    "        - If a parameter does not exist, it will be added. (NOT SURE)\n",
    "        \"\"\"\n",
    "        valid_keys = {\"value\", \"vary\", \"min\", \"max\", \"expr\", \"brute_step\"}\n",
    "\n",
    "        for par in parlist:\n",
    "            # --- normalize input into (name, updates) ---\n",
    "            if isinstance(par, lmfit.Parameter):\n",
    "                name = par.name\n",
    "                updates = {}\n",
    "                if par.value is not None:\n",
    "                    updates[\"value\"] = par.value\n",
    "                if par.vary is not None:\n",
    "                    updates[\"vary\"] = par.vary\n",
    "                # only include min/max if not lmfit defaults\n",
    "                if par.min is not None and np.isfinite(par.min):\n",
    "                    updates[\"min\"] = par.min\n",
    "                if par.max is not None and np.isfinite(par.max):\n",
    "                    updates[\"max\"] = par.max\n",
    "                if par.expr is not None:\n",
    "                    updates[\"expr\"] = par.expr\n",
    "                if par.brute_step is not None:\n",
    "                    updates[\"brute_step\"] = par.brute_step\n",
    "\n",
    "            # --- NEED TO CORRECT THIS PART ----\n",
    "            elif isinstance(par, dict):\n",
    "                if \"name\" not in par:\n",
    "                    msg = 'Dict must contain a \"name\" key'\n",
    "                    logger.error(msg)\n",
    "                    raise ValueError(msg)\n",
    "\n",
    "                name = par[\"name\"]\n",
    "                updates = {}\n",
    "\n",
    "                # only include keys explicitly present in the dict\n",
    "                for k in valid_keys:\n",
    "                    if k in par and par[k] is not None:\n",
    "                        # filter out lmfit defaults if user explicitly passed them\n",
    "                        if k == \"min\" and par[k] == -np.inf:\n",
    "                            continue\n",
    "                        if k == \"max\" and par[k] == np.inf:\n",
    "                            continue\n",
    "                        updates[k] = par[k]\n",
    "\n",
    "                # warn about unsupported keys\n",
    "                unsupported = set(par.keys()) - (valid_keys | {\"name\"})\n",
    "                if unsupported:\n",
    "                    logger.warning(\n",
    "                        f'Ignoring unsupported keys for parameter \"{name}\": {sorted(unsupported)}'\n",
    "                    )\n",
    "            # --- NEED TO CORRECT THIS PART ----\n",
    "\n",
    "\n",
    "            elif isinstance(par, tuple):\n",
    "                # enforce pattern length\n",
    "                name = par[0]\n",
    "                length = len(par)\n",
    "                if length < 2 or length > 7:\n",
    "                    msg = (\n",
    "                        f'Tuple for parameter \"{name}\" must follow the pattern '\n",
    "                        '(NAME, VALUE, VARY, MIN, MAX, EXPR, BRUTE_STEP). '\n",
    "                        f'Got length {length}.'\n",
    "                    )\n",
    "                    logger.error(msg)\n",
    "                    raise ValueError(msg)\n",
    "                updates = {}\n",
    "                if length > 1 and par[1] is not None:\n",
    "                    updates[\"value\"] = par[1]\n",
    "                if length > 2 and par[2] is not None:\n",
    "                    updates[\"vary\"] = par[2]\n",
    "                if length > 3 and par[3] is not None and np.isfinite(par[3]):\n",
    "                    updates[\"min\"] = par[3]\n",
    "                if length > 4 and par[4] is not None and np.isfinite(par[4]):\n",
    "                    updates[\"max\"] = par[4]\n",
    "                if length > 5 and par[5] is not None:\n",
    "                    updates[\"expr\"] = par[5]\n",
    "                if length > 6 and par[6] is not None:\n",
    "                    updates[\"brute_step\"] = par[6]\n",
    "\n",
    "            else:\n",
    "                msg = f'Unsupported type in parlist: {type(par)}'\n",
    "                logger.error(msg)\n",
    "                raise TypeError(msg)\n",
    "\n",
    "            # --- apply updates safely ---\n",
    "            if name in self.initial_params:\n",
    "                # Update only specified keys; preserve everything else\n",
    "                existing = self.initial_params[name]\n",
    "                if updates:\n",
    "                    logger.info(f'Updating parameter \"{name}\" and its attributes in \"initial_params\" parameters...' )\n",
    "                    existing.set(**updates)\n",
    "            else:\n",
    "                # Add new parameter with only provided keys\n",
    "                # value is commonly expected; if omitted, lmfit will default to 0.0\n",
    "                self.initial_params.add(name, **updates)\n",
    "\n",
    "                \n",
    "    ## --- EXPERIMENTAL (NEW) ---###\n",
    "    def _update_params(self, *parlist):\n",
    "        \"\"\"\n",
    "        Update many parameters in `self.initial_params`.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        *parlist : sequence of tuple, dict, Parameter, or dict-of-dicts\n",
    "            - Tuples: (name, value, vary, min, max, expr, brute_step)\n",
    "            - Dicts: {'name': 'sigma', 'value': 0.25, 'vary': True}\n",
    "            - Parameter instances: update using their defined attributes.\n",
    "            - Dict-of-dicts: {'sigma': {'value': 0.25}, 'center': {'vary': False}}\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - Existing parameters are updated in place.\n",
    "        - Only explicitly provided attributes are updated; others remain unchanged.\n",
    "        - If a parameter does not exist, a ValueError is raised.\n",
    "        \"\"\"\n",
    "        valid_keys = {\"value\", \"vary\", \"min\", \"max\", \"expr\", \"brute_step\"}\n",
    "\n",
    "        for par in parlist:\n",
    "            # --- case: dict-of-dicts for multiple parameters ---\n",
    "            if isinstance(par, dict) and all(isinstance(v, dict) for v in par.values()):\n",
    "                for name, attrs in par.items():\n",
    "                    updates = {k: v for k, v in attrs.items()\n",
    "                            if k in valid_keys and v is not None}\n",
    "                    if name not in self.initial_params:\n",
    "                        msg = f'Parameter \"{name}\" not found in initial_params...'\n",
    "                        # logger.error(msg)\n",
    "                        # raise ValueError(msg)\n",
    "                        logger.warning(msg)\n",
    "                    logger.info(f'Updating parameter \"{name}\"...')\n",
    "                    self.initial_params[name].set(**updates)\n",
    "                continue\n",
    "\n",
    "            # --- case: single Parameter instance ---\n",
    "            if isinstance(par, lmfit.Parameter):\n",
    "                name = par.name\n",
    "                updates = {\n",
    "                    \"value\": par.value,\n",
    "                    \"vary\": par.vary,\n",
    "                    \"expr\": par.expr,\n",
    "                    \"brute_step\": par.brute_step,\n",
    "                }\n",
    "                if par.min is not None and np.isfinite(par.min):\n",
    "                    updates[\"min\"] = par.min\n",
    "                if par.max is not None and np.isfinite(par.max):\n",
    "                    updates[\"max\"] = par.max\n",
    "\n",
    "            # --- case: single dict ---\n",
    "            elif isinstance(par, dict):\n",
    "                if \"name\" not in par or not isinstance(par[\"name\"], str):\n",
    "                    msg='Dict must contain a string \"name\" key'\n",
    "                    logger.error(msg)\n",
    "                    raise ValueError()\n",
    "                name = par[\"name\"]\n",
    "                updates = {}\n",
    "                for k in valid_keys:\n",
    "                    if k in par and par[k] is not None:\n",
    "                        if k == \"min\" and par[k] == -np.inf:\n",
    "                            continue\n",
    "                        if k == \"max\" and par[k] == np.inf:\n",
    "                            continue\n",
    "                        updates[k] = par[k]\n",
    "                unsupported = set(par.keys()) - (valid_keys | {\"name\"})\n",
    "                if unsupported:\n",
    "                    logger.warning(\n",
    "                        f'Ignoring unsupported keys for parameter \"{name}\": {sorted(unsupported)}'\n",
    "                    )\n",
    "\n",
    "            # --- case: tuple ---\n",
    "            elif isinstance(par, tuple):\n",
    "                name = par[0]\n",
    "                length = len(par)\n",
    "                if length < 2 or length > 7:\n",
    "                    msg = (\n",
    "                        f'Tuple for parameter \"{name}\" must follow the pattern '\n",
    "                        '(NAME, VALUE, VARY, MIN, MAX, EXPR, BRUTE_STEP). '\n",
    "                        f'Got length {length}.'\n",
    "                    )\n",
    "                    logger.error(msg)\n",
    "                    raise ValueError(msg)\n",
    "                updates = {}\n",
    "                if length > 1 and par[1] is not None:\n",
    "                    updates[\"value\"] = par[1]\n",
    "                if length > 2 and par[2] is not None:\n",
    "                    updates[\"vary\"] = par[2]\n",
    "                if length > 3 and par[3] is not None and np.isfinite(par[3]):\n",
    "                    updates[\"min\"] = par[3]\n",
    "                if length > 4 and par[4] is not None and np.isfinite(par[4]):\n",
    "                    updates[\"max\"] = par[4]\n",
    "                if length > 5 and par[5] is not None:\n",
    "                    updates[\"expr\"] = par[5]\n",
    "                if length > 6 and par[6] is not None:\n",
    "                    updates[\"brute_step\"] = par[6]\n",
    "\n",
    "            else:\n",
    "                msg=f'Unsupported type in parlist: {type(par)}'\n",
    "                logger.error(msg)\n",
    "                raise TypeError(msg)\n",
    "\n",
    "            # # --- apply updates ---\n",
    "            # if name not in self.initial_params:\n",
    "            #     msg = f'Parameter \"{name}\" not found in initial_params'\n",
    "            #     logger.error(msg)\n",
    "            #     raise ValueError(msg)\n",
    "\n",
    "            # if updates:\n",
    "            #     logger.info(f'Updating parameter \"{name}\"...')\n",
    "            #     self.initial_params[name].set(**updates)\n",
    "            \n",
    "            # --- apply updates ---\n",
    "            if name in self.initial_params:\n",
    "                if updates:\n",
    "                    logger.info(f'Updating parameter \"{name}\"...')\n",
    "                    self.initial_params[name].set(**updates)\n",
    "            else:\n",
    "                # Add new parameter with provided attributes\n",
    "                # If no value is given, lmfit defaults to 0.0\n",
    "                logger.warning(f'Adding new parameter \"{name}\" not found in initial_params...')\n",
    "                self.initial_params.add(name, **updates)\n",
    "\n",
    "\n",
    "    # optional alias\n",
    "    def update_params(self, *parlist):\n",
    "        \"\"\"Alias for _update_params.\"\"\"\n",
    "        self._update_params(*parlist)\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # Fitting Functions\n",
    "    # -------------------------------\n",
    "    def _eval(self, params=None):\n",
    "        \"\"\"Evaluate the model with supplied parameters.\"\"\"\n",
    "        if params is None:\n",
    "            params = self.initial_params\n",
    "        self.y_sim = np.zeros_like(self.ydat)\n",
    "        for i in range(self.ny):\n",
    "            self.y_sim[:, i] = self._evaluate_models(self.xdat, params, i)\n",
    "        # logger.info(f'Evaluating lmfit fitting/minimization protocols for the functions...')\n",
    "\n",
    "\n",
    "    def eval(self, x=None, params=None):\n",
    "        \"\"\"Evaluate the model with supplied parameters. (NOT SURE THIS IS GOOD)\"\"\"\n",
    "        # x = x or self.xdat\n",
    "        params = params or self.result.params\n",
    "        x = x if x is not None else self.xdat\n",
    "        y_eval = np.zeros((len(x), self.ny), dtype=float)\n",
    "        for i in range(self.ny):\n",
    "            y_eval[:, i] = self._evaluate_models(x, params, i)   # init values\n",
    "        # logger.info(f'Evaluating lmfit fitting/minimization protocols for the functions...')\n",
    "        return y_eval\n",
    "\n",
    "    def _eval_components_per_dataset(self, i, x=None, params=None):\n",
    "        \"\"\"Return dictionary of name of dataset with dictionary results for each component.\"\"\"\n",
    "        if self.prefix_on:\n",
    "            results = {}\n",
    "            models = self.models\n",
    "            params = params or self.result.params\n",
    "            x = x if x is not None else self.xdat\n",
    "            for midx, model in enumerate(models):\n",
    "                y = self.evaluate_function(\n",
    "                    func=model.func,\n",
    "                    x=x,\n",
    "                    params=params,\n",
    "                    # prefix=self.prefixes[midx],\n",
    "                    prefix=model.prefix,       # cleaner\n",
    "                    i=i,\n",
    "                    # func_kws=self.func_kws_all[midx],\n",
    "                    func_kws=model.func_kws,   # self-contained\n",
    "                )   \n",
    "                results[model.prefix.split('_')[0]] = y         \n",
    "            return results\n",
    "        return {}\n",
    "\n",
    "    def eval_components_per_dataset(self, x=None, params=None):\n",
    "        \"\"\"Return dictionary of name of dataset with dictionary results for each component.\"\"\"\n",
    "        if self.prefix_on:\n",
    "            results = {}\n",
    "            params = params or self.result.params\n",
    "            x = x if x is not None else self.xdat\n",
    "            for i in range(self.ny):\n",
    "                r = self._eval_components_per_dataset(i=i, x=x, params=params)\n",
    "                results[f'{i}'] = r\n",
    "\n",
    "            return results\n",
    "        return {}\n",
    "    \n",
    "    def eval_components(self, x=None, params=None):\n",
    "        \"\"\"Return dictionary of name of dataset with dictionary results for each component.\"\"\"\n",
    "        return self.eval_components_per_dataset(x=x, params=params)\n",
    "\n",
    "    def _r2_safe(self, y_true, y_pred, **kwargs):\n",
    "        \"\"\"Automatically choose sklearn or fallback r2_score_util.\"\"\"\n",
    "        # --- If no NaNs, use sklearn when available ---\n",
    "        if not self.has_nan and r2_score is not None:\n",
    "            try:\n",
    "                return r2_score(y_true, y_pred, **kwargs)\n",
    "            except Exception as exc:\n",
    "                logger.warning(\n",
    "                    f'sklearn `scikit-learn` r2_score failed ({exc}); using `globutils.r2_score_util` instead...'\n",
    "                )\n",
    "\n",
    "        # --- If NaNs or sklearn unavailable, fallback ---\n",
    "        logger.warning(\n",
    "            f'Using nan-safe `globutils.r2_score_util`...'\n",
    "        )\n",
    "        return r2_score_util(y_true, y_pred, **kwargs)\n",
    "\n",
    "    def _residual(self, params):\n",
    "        \"\"\"Return the residual.\"\"\"\n",
    "        self._eval(params=params)\n",
    "        diff = self.y_sim - self.ydat\n",
    "        return diff.flatten()\n",
    "\n",
    "    def _iteration(self, params, it, resid):\n",
    "        \"\"\"Callback during fitting: log RSS and a spinner character.\"\"\"\n",
    "        rss = np.sum(resid**2)\n",
    "        self.rss.append(rss)\n",
    "        char = next(self.thinking)\n",
    "        sys.stdout.write(f'\\rINFO: Fitting {char:s}')\n",
    "        sys.stdout.flush()\n",
    "        # sys.stdout.write(f'\\rFitting ' + char)\n",
    "        # logger.info(sys.stdout.write(f'\\rFitting ' + char))\n",
    "        # sys.stdout.write('\\rRSS: ' + str(rss))\n",
    "        # logger.info(f'Fitting {char:s}')   ## TOO MUCH verbose\n",
    "        # logger.info(f'Fitting {char:s} | RSS={rss:.6e}')   ## TOO MUCH verbose\n",
    "        # logger.info(f'\\rFitting {char:s} | RSS={rss:.6e}')   ## TOO MUCH verbose\n",
    "    \n",
    "        # if self.progress_bar:\n",
    "        #     self.progress_bar.update(1)\n",
    "\n",
    "        # logger.info(\"Iteration %d | RSS=%.6e\", it, rss)\n",
    "\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            method='',\n",
    "            nan_policy='',\n",
    "            verbose=False,\n",
    "            iter_cb=None,\n",
    "            progress=True,\n",
    "            **fit_kws\n",
    "            ):\n",
    "        \"\"\"Fit the model to the data using using lmfit.minimize()\n",
    "\n",
    "        Args:\n",
    "            method (str): Name of the fitting method to use. Defaults to 'leastsq'.\n",
    "                See: https://lmfit.github.io/lmfit-py/fitting.html\n",
    "            nan_policy ({'raise', 'propagate', 'omit'}, optional): NaNs policy\n",
    "            verbose (bool): _description_  Default to False\n",
    "            iter_cb (callable, optional): Callback function called at each fit iteration.\n",
    "                Signature: ``iter_cb(params, iter, resid, *args, **kws)``\n",
    "                Default to None\n",
    "            progress (bool, optional): shows a progress bar (requires tqdm), default to True\n",
    "            **fit_kws (dict, optional): Options to pass to the minimizer being used.\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # --- Use provided arguments or fall back to default instances ---\n",
    "        method = method or self.method\n",
    "        fit_kws = fit_kws or self.fit_kws\n",
    "        iter_cb = iter_cb or self._iteration\n",
    "        nan_policy = nan_policy or self.nan_policy\n",
    "\n",
    "        # # --- Progress bar setup ---\n",
    "        # if progress and not _HAS_TQDM:\n",
    "        #     raise RuntimeError(\n",
    "        #         f'tqdm is required for progress=True. Install it or set progress=False.\\n'\n",
    "        #         f'Installed by `pip install tqdm` or you method of installations'\n",
    "        #         )\n",
    "\n",
    "        # self.progress_bar = tqdm(total=None, desc=\"Fitting\", leave=True) if progress else None\n",
    "\n",
    "        # --- Perform minimization ---\n",
    "        self.thinking = itertools.cycle(['.', '..', '...', '....', '.....'])\n",
    "        self.result = lmfit.minimize(\n",
    "            self._residual,\n",
    "            self.initial_params,\n",
    "            method=method,\n",
    "            nan_policy=nan_policy,\n",
    "            iter_cb=iter_cb,\n",
    "            **fit_kws\n",
    "        )\n",
    "\n",
    "        # if self.progress_bar:\n",
    "        #     self.progress_bar.close()\n",
    "            \n",
    "        # --- Check fit/minimization success ----\n",
    "        self.fit_success = self.result.success\n",
    "\n",
    "        # # --- Verbose output ---\n",
    "        # if verbose:\n",
    "        #     print(f'\\nParameters fit values:')\n",
    "        #     self.result.params.pretty_print()\n",
    "        #     print('Chi2 {:.8e}'.format(self.result.chisqr))\n",
    "        # self._eval(params=self.result.params)\n",
    "\n",
    "        # --- Evaluate with fitted parameters ---\n",
    "        self._eval(params=self.result.params)\n",
    "        self.init_fit = self.eval(params=self.initial_params)\n",
    "        self.best_fit = self.eval(params=self.result.params)\n",
    "        self.residual = self.ydat - self.y_sim\n",
    "\n",
    "        # --- If fit/minimization DONE, compute rsquares ---\n",
    "        if self.fit_success:\n",
    "            logger.info(f'Fitting DONE...')\n",
    "            # self.r2_raw = rsq(self.ydat, self.y_sim, multioutput='raw_values')\n",
    "            # self.r2_mean = rsq(self.ydat, self.y_sim, multioutput='uniform_average')\n",
    "            # self.r2_weighted = rsq(self.ydat, self.y_sim, multioutput='variance_weighted')\n",
    "            self.r2_raw = self._r2_safe(self.ydat, self.y_sim, multioutput='raw_values')\n",
    "            self.r2_mean = self._r2_safe(self.ydat, self.y_sim, multioutput='uniform_average')\n",
    "            self.r2_weighted = self._r2_safe(self.ydat, self.y_sim, multioutput='variance_weighted')\n",
    "\n",
    "        else:\n",
    "            msg = f'Fitting UNSUCCESSFUL...CHECK AGAIN...'\n",
    "            logger.error(msg)             # log the error\n",
    "            raise RuntimeError(msg)       # raise with the messave\n",
    "\n",
    "        # self.r2 = {\n",
    "        #     \"raw\": self.r2_raw,           # per dataset (raw values)\n",
    "        #     \"mean\": self.r2_mean,         # for all (uniform average)\n",
    "        #     \"weighted\": self.r2_weighted, # for all (variance weighted)\n",
    "        # }\n",
    "        self.r2_dict = {\n",
    "            \"raw\": self.r2_raw,           # per dataset (raw values)\n",
    "            \"mean\": self.r2_mean,         # for all (uniform average)\n",
    "            \"weighted\": self.r2_weighted, # for all (variance weighted)\n",
    "        }\n",
    "        self.r2 = copy.deepcopy(self.r2_dict)\n",
    "\n",
    "        # --- Verbose output ---\n",
    "        if self.fit_success and verbose:\n",
    "            self._verbosity()\n",
    "\n",
    "    \n",
    "    def _verbosity(self):\n",
    "        \"\"\"Prnt verbosity of fit parameters\"\"\"\n",
    "        logger.info('Parameters fit values:')\n",
    "        # self.result.params.pretty_print()\n",
    "        self.pretty_print()  # USE THIS\n",
    "        # logger.info(f'Chi2 {self.result.chisqr:.8e}')\n",
    "        # if self.fit_success:\n",
    "        # logger.info(\n",
    "        #     f'Goodness-of-fit metrics — R² (mean): {self.r2_mean:.8f}, R² (weighted): {self.r2_weighted:.8f}'\n",
    "        # )\n",
    "        # logger.info(\n",
    "        #     f'Coefficient of determination: R² = {self.r2_mean:.8f} (uniform mean), R² = {self.r2_weighted:.8f} (variance-weighted)'\n",
    "        # )\n",
    "        logger.info(\n",
    "            f'Coefficient of determination: R² = {self.r2_mean:.8f} (uniform average)...'\n",
    "        )\n",
    "        logger.info(\n",
    "            f'Coefficient of determination: R² = {self.r2_weighted:.8f} (variance-weighted)...'\n",
    "        )\n",
    "\n",
    "\n",
    "    @property\n",
    "    def verbosity(self):\n",
    "        self._verbosity()\n",
    "    \n",
    "    # @property\n",
    "    # def init_fit(self):\n",
    "    #     return self.eval(params=self.initial_params)\n",
    "\n",
    "    # @property\n",
    "    # def best_fit(self):\n",
    "    #     return self.eval(params=self.result.params)\n",
    "    \n",
    "    # @property\n",
    "    # def residual(self):\n",
    "    #     return self.ydat - self.y_sim\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # Pretty Print Helpers\n",
    "    # -------------------------------\n",
    "    def pretty_repr(self, oneline=False):\n",
    "        \"\"\"Return a pretty representation of a Parameters class.\n",
    "\n",
    "        Args:\n",
    "            oneline (bool, optional): If True prints a one-line parameters representation, \n",
    "                default is False.\n",
    "\n",
    "        Returns:\n",
    "            s (str): Parameters representation.\n",
    "\n",
    "        \"\"\"\n",
    "        if oneline:\n",
    "            return self.__repr__()\n",
    "        s = \"Parameters({\\n\"\n",
    "        for key in self.result.params.keys():\n",
    "            s += f\"    '{key}': {self.result.params[key]}, \\n\"\n",
    "        s += \"    })\\n\"\n",
    "        return s\n",
    "    \n",
    "\n",
    "    def pretty_print(self, oneline=False, colwidth=8, precision=4, fmt='g',\n",
    "                    columns=['value', 'min', 'max', 'stderr', 'vary', 'expr',\n",
    "                            'brute_step']):\n",
    "        \"\"\"Pretty-print of parameters data.\n",
    "\n",
    "        Args:\n",
    "            oneline (bool, optional): If True prints a one-line parameters representation,\n",
    "                default is False.\n",
    "            colwidth (int, optional): Column width for all columns specified in `columns`,\n",
    "                default is 8.\n",
    "            precision (int, optional): Number of digits to be printed after floating point, \n",
    "                default is 4.\n",
    "            fmt ({'g', 'e', 'f'}, optional): Single-character numeric formatter. Valid values are: `'g'`\n",
    "                floating point and exponential (default), `'e'` exponential, or `'f'` floating point.\n",
    "            columns (list of str, optional): List of Parameter attribute names to print, \n",
    "                default is to show all attributes.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if oneline:\n",
    "            logger.info(self.pretty_repr(oneline=oneline))\n",
    "            return\n",
    "\n",
    "        name_len = max(len(s) for s in self.result.params)\n",
    "        allcols = ['name'] + columns\n",
    "        title = '{:{name_len}} ' + len(columns) * ' {:>{n}}'\n",
    "        logger.info(title.format(*allcols, name_len=name_len, n=colwidth).title())\n",
    "\n",
    "        numstyle = '{%s:>{n}.{p}{f}}'\n",
    "        otherstyles = dict(\n",
    "            name='{name:<{name_len}} ',\n",
    "            stderr='{stderr!s:>{n}}',\n",
    "            vary='{vary!s:>{n}}',\n",
    "            expr='{expr!s:>{n}}',\n",
    "            brute_step='{brute_step!s:>{n}}'\n",
    "        )\n",
    "        line = ' '.join(otherstyles.get(k, numstyle % k) for k in allcols)\n",
    "\n",
    "        for name, values in sorted(self.result.params.items()):\n",
    "            pvalues = {k: getattr(values, k) for k in columns}\n",
    "            pvalues['name'] = name\n",
    "            if 'stderr' in columns and pvalues['stderr'] is not None:\n",
    "                pvalues['stderr'] = (numstyle % '').format(\n",
    "                    pvalues['stderr'], n=colwidth, p=precision, f=fmt)\n",
    "            elif 'brute_step' in columns and pvalues['brute_step'] is not None:\n",
    "                pvalues['brute_step'] = (numstyle % '').format(\n",
    "                    pvalues['brute_step'], n=colwidth, p=precision, f=fmt)\n",
    "\n",
    "            logger.info(\n",
    "                line.format(name_len=name_len, n=colwidth, p=precision, f=fmt, **pvalues)\n",
    "                )\n",
    "            \n",
    "            \n",
    "    def fit_report(self, params, **kws):\n",
    "        \"\"\"Return a report of the fitting results.\"\"\"\n",
    "        return self.lmfit_report(params, r2_dict=self.r2_dict, **kws)\n",
    "    \n",
    "\n",
    "    def report_fit(self, params, **kws):\n",
    "        \"\"\"Print a report of the fitting results.\"\"\"\n",
    "        print(self.lmfit_report(params, r2_dict=self.r2_dict, **kws)) \n",
    "    \n",
    " \n",
    "    def report(\n",
    "            self,\n",
    "            inpars=None, \n",
    "            modelpars=None, \n",
    "            show_correl=True, \n",
    "            min_correl=0.1,\n",
    "            sort_pars=False, \n",
    "            correl_mode='list'\n",
    "            ):\n",
    "        \"\"\"Return a printable fit report.\n",
    "\n",
    "        The report contains the best-fit values for the parameters and their\n",
    "        uncertainties and correlations.\n",
    "\n",
    "        Args:\n",
    "            inpars (lmfit.Parameters): Input Parameters from fit or MinimizerResult returned from a fit. Default to None.\n",
    "            modelpars (lmfit.Parameters, optional): Known Model Parameters.\n",
    "            show_correl (bool, optional): Whether to show list of sorted correlations (default is True).\n",
    "            min_correl (float, optional): Smallest correlation in absolute value to show (default is 0.1).\n",
    "            sort_pars (bool or callable, optional): Whether to show parameter names sorted in alphanumerical order. \n",
    "                If False (default), then the parameters will be listed in the order they were added to the Parameters \n",
    "                dictionary. If callable, then this (one argument) function is used to extract a comparison key from each list element.\n",
    "            correl_mode ({'list', table'} str, optional): Mode for how to show correlations. Can be either 'list' (default) to show a \n",
    "                sorted (if ``sort_pars`` is True) list of correlation values, or 'table' to show a complete, formatted table of correlations.\n",
    "\n",
    "        Returns:\n",
    "            str: Multi-line text of fit report.\n",
    "        \"\"\"\n",
    "        if inpars is None:\n",
    "            inpars = self.result\n",
    "        reprt = self.lmfit_report(\n",
    "            inpars=inpars, r2_dict=self.r2_dict, modelpars=modelpars, show_correl=show_correl, \n",
    "            min_correl=min_correl, sort_pars=sort_pars, correl_mode=correl_mode\n",
    "            )\n",
    "        \n",
    "        expr = f'{self.composite_model}'\n",
    "        modname = self.wrap_model_reprstring(expr=expr, width=80)\n",
    "        reprt =  f'[[Model]]\\n    {modname}\\n{reprt}'\n",
    "        print(reprt)\n",
    "\n",
    "\n",
    "    \n",
    "    @_ensureMatplotlib\n",
    "    def plot_dat(\n",
    "            self, ax=None, datafmt='o', xlabel=None, ylabel=None, yerr=None, \n",
    "            data_kws=None, ax_kws=None, parse_complex='abs', title='data'\n",
    "            ):\n",
    "        \n",
    "        from matplotlib import pyplot as plt\n",
    "        if data_kws is None:\n",
    "            data_kws = {}\n",
    "        if ax_kws is None:\n",
    "            ax_kws = {}    \n",
    "\n",
    "        # The function reduce_complex will convert complex vectors into real vectors\n",
    "        reduce_complex = get_reducer(parse_complex)\n",
    "\n",
    "        if not isinstance(ax, plt.Axes):\n",
    "            ax = plt.axes(**ax_kws)\n",
    "\n",
    "        xdat = self.data_x              # true x not cut\n",
    "        ydat = np.asarray(self.data_y)  # true y not cut\n",
    "\n",
    "        # if yerr is None and self.weights is not None:\n",
    "        #     yerr = 1.0/self.weights\n",
    "        if yerr is not None:\n",
    "            yerr = np.asarray(yerr)\n",
    "            if ydat.shape != yerr.shape:\n",
    "                # raise ValueError(f'Shape mismatch: {ydat.shape} != {yerr.shape}')\n",
    "                msg=f'Input data and error arrays are different: {ydat.shape} != {yerr.shape}'\n",
    "                logger.error(msg)\n",
    "                raise AttributeError(msg)\n",
    "            # ax.errorbar(\n",
    "            #     xdat, reduce_complex(ydat),\n",
    "            #     yerr=propagate_err(ydat, yerr, parse_complex),\n",
    "            #     fmt=datafmt, label='data', zorder=2, **data_kws\n",
    "            #     )\n",
    "            val = reduce_complex(ydat)\n",
    "            err = propagate_err(ydat, yerr, parse_complex)\n",
    "            if self.ny>1:\n",
    "                for i in range(self.ny):\n",
    "                    # y = val[:, i]\n",
    "                    # dy = err[:, i]\n",
    "                    ax.errorbar(xdat, val[:, i], yerr=err[:, i], fmt=datafmt, label=f'data{i}', zorder=1, **data_kws)\n",
    "            else:\n",
    "                for i in range(self.ny):\n",
    "                    # y = val[:, i]\n",
    "                    # dy = err[:, i]\n",
    "                    ax.errorbar(xdat, val[:, i], yerr=err[:, i], fmt=datafmt, label=f'data', zorder=1, **data_kws)\n",
    "        else:\n",
    "            # ax.plot(xdat, reduce_complex(ydat), datafmt, label='data', zorder=1, **data_kws)\n",
    "            if self.ny>1:\n",
    "                for i in range(self.ny):\n",
    "                    ax.plot(xdat, reduce_complex(ydat)[:, i], datafmt, label=f'data{i}', zorder=1, **data_kws)\n",
    "            else:\n",
    "                ax.plot(xdat, reduce_complex(ydat), datafmt, label='data', zorder=1, **data_kws)\n",
    "\n",
    "\n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "        elif ax.get_title() == '':\n",
    "            ax.set_title('data')\n",
    "        if xlabel is None:\n",
    "            ax.set_xlabel('x')\n",
    "        else:\n",
    "            ax.set_xlabel(xlabel)\n",
    "        if ylabel is None:\n",
    "            ax.set_ylabel('raw data')\n",
    "        else:\n",
    "            ax.set_ylabel(ylabel)\n",
    "        ax.legend()\n",
    "\n",
    "        return ax\n",
    "\n",
    "\n",
    "    @_ensureMatplotlib\n",
    "    def plot_init(\n",
    "            self, ax=None, datafmt='o', initfmt='--', xlabel=None, ylabel=None, yerr=None, show_init_dat=True,\n",
    "            numpoints=None, data_kws=None, init_kws=None, ax_kws=None, parse_complex='abs', title='initial fit'\n",
    "            ):\n",
    "        \n",
    "        from matplotlib import pyplot as plt\n",
    "        if data_kws is None:\n",
    "            data_kws = {}\n",
    "        if init_kws is None:\n",
    "            init_kws = {}\n",
    "        if ax_kws is None:\n",
    "            ax_kws = {}    \n",
    "\n",
    "        # The function reduce_complex will convert complex vectors into real vectors\n",
    "        reduce_complex = get_reducer(parse_complex)\n",
    "\n",
    "        if not isinstance(ax, plt.Axes):\n",
    "            ax = plt.axes(**ax_kws)\n",
    "\n",
    "        x_array = self.data_x              # true x not cut\n",
    "        # x_array = self.xdat                # cut x\n",
    "\n",
    "        # make a dense array for x-axis if data is not dense\n",
    "        if numpoints is not None and len(x_array) < numpoints:\n",
    "            x_array_dense = np.linspace(min(x_array), max(x_array), numpoints)\n",
    "        else:\n",
    "            x_array_dense = x_array\n",
    "\n",
    "        if show_init_dat:\n",
    "            ax = self.plot_dat(\n",
    "                ax=ax, datafmt=datafmt, xlabel=xlabel, ylabel=ylabel, yerr=yerr, \n",
    "                data_kws=data_kws, ax_kws=ax_kws, parse_complex=parse_complex, title=title\n",
    "                )\n",
    "\n",
    "        # self._eval_init(xdat=x_array_dense, params=self.initial_params)\n",
    "        # y_eval_init = self.y_eval_init\n",
    "        y_eval_init = self.eval(x=x_array_dense, params=self.initial_params)\n",
    "        # ax.plot(x_array_dense, reduce_complex(y_eval_init), initfmt, label='initial fit', zorder=2, **init_kws)\n",
    "        if self.ny>1:\n",
    "            for i in range(self.ny):\n",
    "                ax.plot(x_array_dense, reduce_complex(y_eval_init)[:, i], initfmt, label=f'init{i}', zorder=2, **init_kws)\n",
    "        else:\n",
    "            ax.plot(x_array_dense, reduce_complex(y_eval_init), initfmt, label='init', zorder=2, **init_kws)\n",
    "\n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "        elif ax.get_title() == '':\n",
    "            ax.set_title('initial fit')\n",
    "        if xlabel is None:\n",
    "            ax.set_xlabel('x')\n",
    "        else:\n",
    "            ax.set_xlabel(xlabel)\n",
    "        if ylabel is None:\n",
    "            ax.set_ylabel('initial curve')\n",
    "        else:\n",
    "            ax.set_ylabel(ylabel)\n",
    "        ax.legend()\n",
    "\n",
    "        return ax\n",
    "    \n",
    "\n",
    "    @_ensureMatplotlib\n",
    "    def plot_fit(\n",
    "            self, ax=None, datafmt='o', fitfmt='-', initfmt='--', xlabel=None, ylabel=None, yerr=None, numpoints=None,\n",
    "            data_kws=None, fit_kws=None, init_kws=None, ax_kws=None, show_init=False, show_init_dat=False, parse_complex='abs', title='best fit'\n",
    "            ):\n",
    "\n",
    "        from matplotlib import pyplot as plt\n",
    "        if fit_kws is None:\n",
    "            fit_kws = {}\n",
    "        if ax_kws is None:\n",
    "            ax_kws = {}\n",
    "\n",
    "        # The function reduce_complex will convert complex vectors into real vectors\n",
    "        reduce_complex = get_reducer(parse_complex)\n",
    "\n",
    "        if not isinstance(ax, plt.Axes):\n",
    "            ax = plt.axes(**ax_kws)\n",
    "\n",
    "        x_array = self.data_x              # true x not cut\n",
    "        # x_array = self.xdat                # cut x\n",
    "\n",
    "        # make a dense array for x-axis if data is not dense\n",
    "        if numpoints is not None and len(x_array) < numpoints:\n",
    "            x_array_dense = np.linspace(min(x_array), max(x_array), numpoints)\n",
    "        else:\n",
    "            x_array_dense = x_array\n",
    "\n",
    "        ax = self.plot_dat(\n",
    "            ax=ax, datafmt=datafmt, xlabel=xlabel, ylabel=ylabel, yerr=yerr, \n",
    "            data_kws=data_kws, ax_kws=ax_kws, parse_complex=parse_complex, title=title\n",
    "            )\n",
    "                \n",
    "        if show_init:\n",
    "            ax = self.plot_init(\n",
    "                ax=ax, datafmt=datafmt, initfmt=initfmt, xlabel=xlabel, ylabel=ylabel, yerr=yerr, show_init_dat=show_init_dat,\n",
    "                numpoints=numpoints, data_kws=data_kws, init_kws=init_kws, ax_kws=ax_kws, parse_complex=parse_complex, title=title\n",
    "            )\n",
    "            \n",
    "        y_eval_fit = self.eval(x=x_array_dense, params=self.result.params)\n",
    "        # ax.plot(x_array_dense, reduce_complex(y_eval_fit), fitfmt, label='best fit', zorder=3, **fit_kws)\n",
    "        if self.ny>1:\n",
    "            for i in range(self.ny):\n",
    "                ax.plot(x_array_dense, reduce_complex(y_eval_fit)[:, i], fitfmt, label=f'fit{i}', zorder=3, **fit_kws)\n",
    "        else:\n",
    "            ax.plot(x_array_dense, reduce_complex(y_eval_fit), fitfmt, label='fit', zorder=3, **fit_kws)\n",
    "    \n",
    "\n",
    "\n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "        elif ax.get_title() == '':\n",
    "            ax.set_title('best fit')\n",
    "        if xlabel is None:\n",
    "            ax.set_xlabel('x')\n",
    "        else:\n",
    "            ax.set_xlabel(xlabel)\n",
    "        if ylabel is None:\n",
    "            ax.set_ylabel('best fit')\n",
    "        else:\n",
    "            ax.set_ylabel(ylabel)\n",
    "        ax.legend()\n",
    "        return ax\n",
    "    \n",
    "    \n",
    "    @_ensureMatplotlib\n",
    "    def plot_residuals(\n",
    "            self, ax=None, datafmt='o', fitfmt='-', xlabel=None, ylabel=None, yerr=None, \n",
    "            data_kws=None, fit_kws=None, ax_kws=None, parse_complex='abs', title='residuals'\n",
    "            ):\n",
    "        \n",
    "        from matplotlib import pyplot as plt\n",
    "        if data_kws is None:\n",
    "            data_kws = {}\n",
    "        if fit_kws is None:\n",
    "            fit_kws = {}\n",
    "        if ax_kws is None:\n",
    "            ax_kws = {}\n",
    "\n",
    "        # The function reduce_complex will convert complex vectors into real vectors\n",
    "        reduce_complex = get_reducer(parse_complex)\n",
    "\n",
    "        if not isinstance(ax, plt.Axes):\n",
    "            ax = plt.axes(**ax_kws)\n",
    "\n",
    "        ax.axhline(0, **fit_kws, zorder=4, color='k')\n",
    "\n",
    "        # xdat = self.data_x              # true x not cut\n",
    "        xdat = np.asarray(self.xdat)      # cut x\n",
    "        # ydat = np.asarray(self.data_y)  # true y not cut\n",
    "        ydat = np.asarray(self.ydat)      # cut y           \n",
    "\n",
    "        # ax = self.plot_dat(\n",
    "        #     ax=ax, datafmt=datafmt, xlabel=xlabel, ylabel=ylabel, yerr=yerr, \n",
    "        #     data_kws=data_kws, ax_kws=ax_kws, parse_complex=parse_complex, title=title\n",
    "        #     )\n",
    "        \n",
    "        y_eval_fit = self.y_sim\n",
    "        # y_eval_fit = self.eval(x=xdat, params=self.result.params)\n",
    "        # y_eval_fit = self.eval()\n",
    "        \n",
    "        residuals = reduce_complex(ydat) - reduce_complex(y_eval_fit)\n",
    "\n",
    "        # if yerr is None and self.weights is not None:\n",
    "        #     yerr = 1.0/self.weights\n",
    "        if yerr is not None:\n",
    "            yerr = np.asarray(yerr)\n",
    "            if ydat.shape != yerr.shape:\n",
    "                # raise ValueError(f'Shape mismatch: {ydat.shape} != {yerr.shape}')\n",
    "                msg=f'Input data and error arrays are different: {ydat.shape} != {yerr.shape}'\n",
    "                logger.error(msg)\n",
    "                raise AttributeError(msg)\n",
    "            # ax.errorbar(\n",
    "            #     xdat, residuals,\n",
    "            #     yerr=propagate_err(ydat, yerr, parse_complex),\n",
    "            #     fmt=datafmt, label='resid', zorder=4, **data_kws\n",
    "            #     )\n",
    "            err = propagate_err(ydat, yerr, parse_complex)\n",
    "            if self.ny>1:\n",
    "                for i in range(self.ny):\n",
    "                    # y = residuals[:, i]\n",
    "                    # dy = err[:, i]\n",
    "                    ax.errorbar(xdat, residuals[:, i], yerr=err[:, i], fmt=datafmt, label=f'resid{i}', zorder=4, **data_kws)\n",
    "            else:\n",
    "                 for i in range(self.ny):\n",
    "                    # y = residuals[:, i]\n",
    "                    # dy = err[:, i]\n",
    "                    ax.errorbar(xdat, residuals[:, i], yerr=err[:, i], fmt=datafmt, label=f'resid', zorder=4, **data_kws)               \n",
    "        else:\n",
    "            # ax.plot(xdat, residuals, datafmt, label='resid', zorder=4, **data_kws)\n",
    "            if self.ny>1:\n",
    "                for i in range(self.ny):\n",
    "                    ax.plot(xdat, residuals[:, i], datafmt, label=f'resid{i}', zorder=4, **data_kws)\n",
    "            else:\n",
    "                ax.plot(xdat, residuals, datafmt, label='resid', zorder=4, **data_kws)\n",
    "\n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "        elif ax.get_title() == '':\n",
    "            ax.set_title('residuals')\n",
    "        if xlabel is None:\n",
    "            ax.set_xlabel('x')\n",
    "        else:\n",
    "            ax.set_xlabel(xlabel)\n",
    "        if ylabel is None:\n",
    "            ax.set_ylabel('residuals')\n",
    "        else:\n",
    "            ax.set_ylabel(ylabel)\n",
    "        ax.legend()\n",
    "        return ax\n",
    "    \n",
    "     \n",
    "    @_ensureMatplotlib\n",
    "    def plot(\n",
    "        self, datafmt='o', fitfmt='-', initfmt='--', xlabel=None, ylabel=None, yerr=None, numpoints=None, fig=None, \n",
    "        data_kws=None,fit_kws=None, init_kws=None, ax_res_kws=None, ax_fit_kws=None,fig_kws=None, show_init=False, \n",
    "        show_init_dat=False, parse_complex='abs', title=None\n",
    "        ):\n",
    "        \"\"\"Plot the fit results and residuals using matplotlib.\n",
    "\n",
    "        The method will produce a matplotlib figure (if package available)\n",
    "        with both results of the fit and the residuals plotted. If the fit\n",
    "        model included weights, errorbars will also be plotted. To show\n",
    "        the initial conditions for the fit, pass the argument\n",
    "        ``show_init=True``.\n",
    "\n",
    "        Args:\n",
    "            datafmt (str, optional): Matplotlib format string for data points.\n",
    "            fitfmt (str, optional): Matplotlib format string for fitted curve.\n",
    "            initfmt (str, optional): Matplotlib format string for initial conditions for the fit.\n",
    "            xlabel (str, optional): Matplotlib format string for labeling the x-axis.\n",
    "            ylabel (str, optional): Matplotlib format string for labeling the y-axis.\n",
    "            yerr (numpy.ndarray, optional): Array of uncertainties for data array.\n",
    "            numpoints (int, optional): If provided, the final and initial fit curves are evaluated\n",
    "                not only at data points, but refined to contain `numpoints` points in total.\n",
    "            fig  (matplotlib.figure.Figure, optional): The figure to plot on. The default is None, \n",
    "                which means use the current pyplot figure or create one if there is none.\n",
    "            data_kws (dict, optional): Keyword arguments passed to the plot function for data points.\n",
    "            fit_kws (dict, optional): Keyword arguments passed to the plot function for fitted curve.\n",
    "            init_kws (dict, optional): Keyword arguments passed to the plot function for the initial\n",
    "                conditions of the fit.\n",
    "            ax_res_kws (dict, optional): Keyword arguments for the axes for the residuals plot.\n",
    "            ax_fit_kws (dict, optional): Keyword arguments for the axes for the fit plot.\n",
    "            fig_kws (dict, optional): Keyword arguments for a new figure, if a new one is created.\n",
    "            show_init (bool, optional): Whether to show the initial conditions for the fit \n",
    "                (default is False).\n",
    "            show_init_dat (bool, optional): Whether to plot raw data in the initial conditions for the fit \n",
    "                (default is False).        \n",
    "            parse_complex ({'abs', 'real', 'imag', 'angle'}, optional): How to reduce complex data for plotting. \n",
    "                Options are one of: `'abs'` (default), `'real'`, `'imag'`, or `'angle'`, which correspond to the \n",
    "                NumPy functions with the same name.\n",
    "            title (str, optional): Matplotlib format string for figure title.\n",
    "\n",
    "        Returns:\n",
    "        matplotlib.figure.Figure\n",
    "\n",
    "        See Also\n",
    "        --------\n",
    "        LmfitGlobal.plot_init : Plot the init results using matplotlib.\n",
    "        LmfitGlobal.plot_fit :  Plot the fit results using matplotlib.\n",
    "        LmfitGlobal.plot_residuals : Plot the fit residuals using matplotlib.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The method combines `LmfitGlobal.plot_fit`, `LmfitGlobal.plot_init` and\n",
    "        `LmfitGlobal.plot_residuals`.\n",
    "\n",
    "        If `yerr` is specified or if the fit model included weights, then\n",
    "        `matplotlib.axes.Axes.errorbar` is used to plot the data. If\n",
    "        `yerr` is not specified and the fit includes weights, `yerr` set\n",
    "        to ``1/self.weights``.\n",
    "\n",
    "        If model returns complex data, `yerr` is treated the same way that\n",
    "        weights are in this case.\n",
    "\n",
    "        If `fig` is None then `matplotlib.pyplot.figure(**fig_kws)` is\n",
    "        called, otherwise `fig_kws` is ignored.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        from matplotlib import pyplot as plt\n",
    "        if data_kws is None:\n",
    "            data_kws = {}\n",
    "        if fit_kws is None:\n",
    "            fit_kws = {}\n",
    "        if init_kws is None:\n",
    "            init_kws = {}\n",
    "        if ax_res_kws is None:\n",
    "            ax_res_kws = {}\n",
    "        if ax_fit_kws is None:\n",
    "            ax_fit_kws = {}\n",
    "\n",
    "        # make a square figure with side equal to the default figure's x-size\n",
    "        figxsize = plt.rcParams['figure.figsize'][0]\n",
    "        fig_kws_ = dict(figsize=(figxsize, figxsize))\n",
    "        if fig_kws is not None:\n",
    "            fig_kws_.update(fig_kws)\n",
    "\n",
    "        if not isinstance(fig, plt.Figure):\n",
    "            fig = plt.figure(**fig_kws_)\n",
    "\n",
    "        gs = plt.GridSpec(nrows=2, ncols=1, height_ratios=[1, 4])\n",
    "        ax_res = fig.add_subplot(gs[0], **ax_res_kws)\n",
    "        ax_fit = fig.add_subplot(gs[1], sharex=ax_res, **ax_fit_kws)\n",
    "\n",
    "        # gs = plt.GridSpec(nrows=2, ncols=1, height_ratios=[4, 1])\n",
    "        # ax_fit = fig.add_subplot(gs[0], **ax_fit_kws)\n",
    "        # ax_res = fig.add_subplot(gs[1], **ax_res_kws)\n",
    "\n",
    "        self.plot_fit(\n",
    "            ax=ax_fit, datafmt=datafmt, fitfmt=fitfmt, yerr=yerr,initfmt=initfmt, \n",
    "            xlabel=xlabel, ylabel=ylabel, numpoints=numpoints, data_kws=data_kws,\n",
    "            fit_kws=fit_kws, init_kws=init_kws, ax_kws=ax_fit_kws, show_init=show_init, \n",
    "            show_init_dat=show_init_dat, parse_complex=parse_complex,title=''\n",
    "            )\n",
    "        \n",
    "        self.plot_residuals(\n",
    "            ax=ax_res, datafmt=datafmt, yerr=yerr, data_kws=data_kws, fit_kws=fit_kws,\n",
    "            ax_kws=ax_res_kws, parse_complex=parse_complex, title=title\n",
    "            )\n",
    "        \n",
    "        plt.setp(ax_res.get_xticklabels(), visible=False)\n",
    "        ax_fit.set_title('')\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f0224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-(py3.12)",
   "language": "python",
   "name": "py3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

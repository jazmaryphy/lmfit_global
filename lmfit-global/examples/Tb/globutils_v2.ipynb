{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19cfc375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "import logging\n",
    "import inspect\n",
    "import operator\n",
    "import numpy as np\n",
    "import functools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db93cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _r2_score(y_true, y_pred, multioutput='uniform_average'):\n",
    "    \"\"\":math:`R^2` (coefficient of determination) regression score function.\n",
    "\n",
    "    Best possible score is 1.0 and it can be negative (because the\n",
    "    model can be arbitrarily worse). In the general case when the true y is\n",
    "    non-constant, a constant model that always predicts the average y\n",
    "    disregarding the input features would get a :math:`R^2` score of 0.0.\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): True/Correct/Experimental data in ndarray-like of shape \n",
    "            (n_samples,) or (n_samples, n_outputs).\n",
    "        y_pred (numpt.ndarray): Estimated/Target/Predicted values in ndarray-like of shape \n",
    "            (n_samples,) or (n_samples, n_outputs).\n",
    "             \n",
    "        multioutput (str, optional): Defines aggregating of multiple output scores. \n",
    "            Defaults to 'uniform_average'. Other options are:\n",
    "\n",
    "            'raw_values' :\n",
    "                Returns a full set of scores in case of multioutput input.\n",
    "\n",
    "            'uniform_average' :\n",
    "                Scores of all outputs are averaged with uniform weight.\n",
    "\n",
    "            'variance_weighted' :\n",
    "                Scores of all outputs are averaged, weighted by the variances\n",
    "                of each individual output.\n",
    "\n",
    "    Returns:\n",
    "        (float or ndarray of floats): The :math:`R^2` score or ndarray of scores \n",
    "        if 'multioutput' is 'raw_values'.\n",
    "    \"\"\"\n",
    "    \n",
    "    def r_square_nan(y, f):\n",
    "        \"\"\"Calculate the :math:`R^2` statistic.\n",
    "\n",
    "        Args:\n",
    "            y (array-like): Array of observed data.\n",
    "            f (array-like): Array of fitted data (model predictions).\n",
    "\n",
    "        Returns:\n",
    "            float: :math:`R^2` statistic.\n",
    "        \"\"\"\n",
    "        # Convert inputs to numpy arrays if they aren't already\n",
    "        y = np.array(y)\n",
    "        f = np.array(f)\n",
    "        # Mask to ignore NaN values\n",
    "        mask = ~np.isnan(y)\n",
    "        # mask = ~np.isnan(y) & ~np.isnan(f)\n",
    "\n",
    "        y_mean = np.mean(y[mask])\n",
    "        ss_res = np.sum((y[mask] - f[mask]) ** 2)\n",
    "        ss_tot = np.sum((y[mask] - y_mean) ** 2)\n",
    "\n",
    "        r_squared = 1 - (ss_res / ss_tot)\n",
    "        return r_squared, ss_tot\n",
    "    \n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    # Normalize to 2-D\n",
    "    if y_true.ndim==1:\n",
    "        y_true = y_true.reshape(-1, 1)\n",
    "        y_pred = y_pred.reshape(-1, 1)\n",
    "\n",
    "    if y_true.ndim != 2 or y_pred.ndim != 2:\n",
    "        raise ValueError(f'`y_true` and `y_pred` must be 2-D after reshaping')\n",
    "    if y_true.ndim != y_pred.ndim:\n",
    "        raise ValueError(\n",
    "            f'Shape mismatch: `y_true` has ndim={y_true.ndim}, '\n",
    "            f'`y_pred` has ndim={y_pred.ndim}'\n",
    "        )\n",
    "\n",
    "    r2_scores = []\n",
    "    ss_tot_list = []\n",
    "\n",
    "    # Compute per-output R^2 and ss_tot\n",
    "    for i in range(y_true.shape[1]):\n",
    "        r2, ss_tot = r_square_nan(y_true[:, i], y_pred[:, i])\n",
    "        r2_scores.append(r2)\n",
    "        ss_tot_list.append(ss_tot)\n",
    "\n",
    "    r2_scores = np.array(r2_scores)\n",
    "    ss_tot_list = np.array(ss_tot_list)\n",
    "\n",
    "    if multioutput == 'raw_values':\n",
    "        return r2_scores\n",
    "    elif multioutput == 'uniform_average':\n",
    "        return np.mean(r2_scores)\n",
    "    elif multioutput == 'variance_weighted':\n",
    "        weights = ss_tot_list / np.sum(ss_tot_list)\n",
    "        return np.sum(weights * r2_scores)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid multioutput option\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e942d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_model_reprstring(expr, width=80, indent=4):\n",
    "    \"\"\"Wrap a composite model expression string at operators for readability.\n",
    "\n",
    "    Args:\n",
    "        expr (str): The composite model expression string.\n",
    "        width (int, optional): Max line width (default is 80).\n",
    "        indent (int, optional): Spaces to indent continuation lines (default is 4)\n",
    "\n",
    "    Returns:\n",
    "        str: Wrapped expression string.\n",
    "    \"\"\"\n",
    "    tokens = re.split(r'(\\+|\\-|\\*|/)', expr)  # split but keep operators\n",
    "    lines = []\n",
    "    current = \"\"\n",
    "\n",
    "    for tok in tokens:\n",
    "        if len(current) + len(tok) + 1 > width:\n",
    "            lines.append(current.rstrip())\n",
    "            current = \" \" * indent + tok\n",
    "        else:\n",
    "            current += tok\n",
    "    if current:\n",
    "        lines.append(current.rstrip())\n",
    "\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79933846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ax_kws(ax, ax_kws=None):\n",
    "    \"\"\"Apply axis customizations from a dictionary.\n",
    "\n",
    "    Args:\n",
    "        ax (matplotlib.axes.Axes): Axis object to customize.\n",
    "        ax_kws (dict, optional): Keys are method names or special strings, values are args/kwargs.\n",
    "        Examples:\n",
    "            {\n",
    "              \"figsize\": None,  \n",
    "              \"minorticks_on\": {},\n",
    "              \"tick_params_major\": {\"which\":\"major\",\"direction\":\"in\",\"length\":8,\"width\":1.0,\"top\":True,\"right\":True},\n",
    "              \"tick_params_minor\": {\"which\":\"minor\",\"direction\":\"in\",\"length\":4,\"width\":1.0,\"top\":True,\"right\":True},\n",
    "              \"tick_params_xlabels\": {\"axis\":\"x\",\"labelsize\":18,\"labelcolor\":\"k\"},\n",
    "              \"tick_params_ylabels\": {\"axis\":\"y\",\"labelsize\":18,\"labelcolor\":\"k\"},\n",
    "              \"set_xscale\": {\"value\":\"log\"},\n",
    "              \"set_xlim\": ([1.0,200],),\n",
    "              \"axhline\": {\"y\":0,\"color\":\"black\",\"linestyle\":\"dotted\"},\n",
    "              \"axvline\": {\"x\":12,\"color\":\"black\",\"linestyle\":\"dashed\"},\n",
    "              \"formatter\": \"log_plain\",\n",
    "              \"spines\": {\"linewidth\": 1.5, \"color\": \"black\"}\n",
    "            }\n",
    "    \"\"\"\n",
    "    import matplotlib.ticker as ticker\n",
    "\n",
    "    if not ax_kws:\n",
    "        return\n",
    "\n",
    "    for method_name, args in ax_kws.items():\n",
    "        # --- Special case: formatter ---\n",
    "        if method_name == \"formatter\":\n",
    "            if args == \"log_plain\":\n",
    "                ax.xaxis.set_major_formatter(ticker.LogFormatter(base=10, labelOnlyBase=False))\n",
    "            elif callable(args):\n",
    "                ax.xaxis.set_major_formatter(args)\n",
    "            continue\n",
    "\n",
    "        # --- Tick params (major/minor/labels) ---\n",
    "        if method_name in (\"tick_params_major\", \"tick_params_minor\",\n",
    "                           \"tick_params_xlabels\", \"tick_params_ylabels\"):\n",
    "            ax.tick_params(**args)\n",
    "            continue\n",
    "\n",
    "        # --- Spines ---\n",
    "        if method_name == \"spines\":\n",
    "            for spine in ax.spines.values():\n",
    "                if \"linewidth\" in args:\n",
    "                    spine.set_linewidth(args[\"linewidth\"])\n",
    "                if \"color\" in args:\n",
    "                    spine.set_color(args[\"color\"])\n",
    "            continue\n",
    "\n",
    "        # --- Figure size ---\n",
    "        if method_name == \"figsize\":\n",
    "            if args is not None:  # only apply if not None\n",
    "                fig = ax.figure\n",
    "                fig.set_size_inches(*args)\n",
    "            continue\n",
    "\n",
    "        # --- Normal methods ---\n",
    "        if hasattr(ax, method_name):\n",
    "            method = getattr(ax, method_name)\n",
    "            if isinstance(args, dict):\n",
    "                method(**args)\n",
    "            elif isinstance(args, (list, tuple)):\n",
    "                method(*args)\n",
    "            else:\n",
    "                method(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7e13d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_2darray(arr):\n",
    "    \"\"\"Ensure array is always shape (N, M), and 1D becomes (N, 1).\n",
    "\n",
    "    Args:\n",
    "        arr (list): Numpy array in 1 dimension or list or list of lists\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: 2d array of shape(N,M)\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    \n",
    "    # Make it 2D\n",
    "    arr = np.atleast_2d(arr)\n",
    "\n",
    "    # If row vector → convert to column vector\n",
    "    if arr.shape[0] == 1 and arr.ndim == 2:\n",
    "        arr = arr.T\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "def pad_list_with_nan(lst):\n",
    "    \"\"\"\n",
    "    Pads a list of lists with NaN to ensure all inner lists have the same length.\n",
    "\n",
    "    Args:\n",
    "        arr (lst): List of lists of float or int.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 2D array with shorter rows padded with np.nan.\n",
    "                    If all rows are the same length, returns the array as-is.\n",
    "    \"\"\"\n",
    "    row_lengths = [len(row) for row in lst]\n",
    "    if len(set(row_lengths)) == 1:\n",
    "        # All rows have the same length — no padding needed\n",
    "        return np.array(lst, dtype=float)\n",
    "\n",
    "    max_len = max(row_lengths)\n",
    "    pad_arr = np.full((len(lst), max_len), np.nan)\n",
    "    for i, row in enumerate(lst):\n",
    "        pad_arr[i, :len(row)] = row\n",
    "    return pad_arr\n",
    "\n",
    "\n",
    "def merge_xyerr_data_numpy(xdat_lst, ydat_lst, yerr_lst=None):\n",
    "    \"\"\"\n",
    "    Merges multiple (x, y, yerr) datasets into a unified NumPy array with shared x-axis.\n",
    "    Missing values are filled with np.nan. If yerr_lst is None, error columns are omitted.\n",
    "\n",
    "    Args:\n",
    "        xdat_lst (list of np.ndarray): List of x arrays.\n",
    "        ydat_lst (list of np.ndarray): List of y arrays.\n",
    "        yerr_lst (list of np.ndarray or None): List of error arrays or None.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 2D array with columns: x, y_1, yerr_1, y_2, yerr_2, ...\n",
    "    \"\"\"\n",
    "    all_x = np.unique(np.concatenate(xdat_lst))\n",
    "    N = len(xdat_lst)\n",
    "\n",
    "    y_merged = np.full((len(all_x), N), np.nan)\n",
    "    yerr_merged = None if yerr_lst is None else np.full((len(all_x), N), np.nan)\n",
    "\n",
    "    for i in range(N):\n",
    "        x = xdat_lst[i]\n",
    "        y = ydat_lst[i]\n",
    "        for xi, yi in zip(x, y):\n",
    "            idx = np.where(all_x == xi)[0]\n",
    "            if idx.size > 0:\n",
    "                y_merged[idx[0], i] = yi\n",
    "        if yerr_lst is not None:\n",
    "            for xi, ei in zip(x, yerr_lst[i]):\n",
    "                idx = np.where(all_x == xi)[0]\n",
    "                if idx.size > 0:\n",
    "                    yerr_merged[idx[0], i] = ei\n",
    "\n",
    "    # Stack into final output: [x | y_1 | yerr_1 | y_2 | yerr_2 | ...]\n",
    "    if yerr_lst is not None:\n",
    "        combined = [all_x.reshape(-1, 1)]\n",
    "        for i in range(N):\n",
    "            combined.append(y_merged[:, i].reshape(-1, 1))\n",
    "            combined.append(yerr_merged[:, i].reshape(-1, 1))\n",
    "        return np.hstack(combined)\n",
    "    else:\n",
    "        return np.column_stack((all_x, y_merged))\n",
    "    \n",
    "\n",
    "def build_composite_model(model_lst, op_list):\n",
    "    \"\"\"\n",
    "    Build a composite lmfit.Model from a list of models and operators.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_lst : list of lmfit.Model\n",
    "        Models to combine.\n",
    "    op_list : list of str\n",
    "        Operators ('+', '-', '*', '/') of length len(model_lst)-1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    composite_model : lmfit.Model\n",
    "        Composite model object.\n",
    "    \"\"\"\n",
    "    op_map = {\n",
    "        '+': operator.add,\n",
    "        '-': operator.sub,\n",
    "        '*': operator.mul,\n",
    "        '/': operator.truediv,\n",
    "    }\n",
    "\n",
    "    composite_model = ft.reduce(\n",
    "        lambda x, y: op_map[y[1]](x, y[0]),\n",
    "        zip(model_lst[1:], op_list),\n",
    "        model_lst[0]\n",
    "    )\n",
    "    return composite_model\n",
    "    \n",
    "    \n",
    "def build_composite_model_expr(model_lst, op_list):\n",
    "    \"\"\"\n",
    "    Build a human-readable expression string for the composite model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_lst : list of lmfit.Model\n",
    "        Models to describe.\n",
    "    op_list : list of str\n",
    "        Operators ('+', '-', '*', '/') of length len(model_lst)-1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    expr : str\n",
    "        String representation of the composite function with arguments.\n",
    "    \"\"\"\n",
    "    expr_parts = []\n",
    "    for i, mdl in enumerate(model_lst):\n",
    "        func = mdl.func\n",
    "        sig = inspect.signature(func)\n",
    "        args = [pname for pname in sig.parameters]\n",
    "        arg_str = ', '.join(args)\n",
    "        func_str = f'{func.__name__}({arg_str})'\n",
    "        expr_parts.append(func_str)\n",
    "        if i < len(op_list):\n",
    "            expr_parts.append(op_list[i])\n",
    "    return ' '.join(expr_parts)\n",
    "\n",
    "\n",
    "def _evaluate_function(function, xdat, params, prefix, i, kws=None):\n",
    "    \"\"\"\n",
    "    Evaluate a single function with parameters from lmfit and fixed options.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    function : callable\n",
    "        The function to evaluate (e.g. gaussian, exponential).\n",
    "    xdat : array-like\n",
    "        Input x data.\n",
    "    params : lmfit.Parameters\n",
    "        Composite parameter set containing prefixed parameter names.\n",
    "    prefix : str\n",
    "        Prefix for this function (e.g. 'c0_', 'c1_').\n",
    "    i : int\n",
    "        Index for dataset (e.g. 0 for first dataset).\n",
    "    kws : dict, optional\n",
    "        Fixed options (non-fit parameters like form='erf', gamma=5.0).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        Evaluated function values.\n",
    "    \"\"\"\n",
    "    if kws is None:\n",
    "        kws = {}\n",
    "\n",
    "    # Get ordered function parameters\n",
    "    fn_pars = list(inspect.signature(function).parameters.keys())\n",
    "\n",
    "    # First parameter is the x variable name\n",
    "    xname = fn_pars[0]\n",
    "\n",
    "    # Remaining parameters\n",
    "    argnames = fn_pars[1:]\n",
    "\n",
    "    kwargs = {}\n",
    "    for name in argnames:\n",
    "        # Case 1: name is in lmfit parameter set → pull from params\n",
    "        param_key = f\"{prefix}{name}_{i}\"\n",
    "        if param_key in params:\n",
    "            kwargs[name] = params[param_key].value\n",
    "\n",
    "        # Case 2: name is in extra kwargs (fixed parameters)\n",
    "        elif name in kws:\n",
    "            kwargs[name] = kws[name]\n",
    "\n",
    "        # Case 3: leave it alone; function will handle default value\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # Evaluate function safely\n",
    "    return function(xdat, **kwargs)\n",
    "\n",
    "\n",
    "def evaluate_function(func, x, params, prefix, i, func_kws=None):\n",
    "    \"\"\"Evaluate a single function with parameters from lmfit and `func` keyward arguments (if any).\n",
    "\n",
    "    Args:\n",
    "        func (callable): The function to evaluate\n",
    "        x (array, list of floats): Array-like of x data\n",
    "        params (lmfit.Parameters): Contains the Parameters for the model.\n",
    "        prefix (str): Prefix for the function `func` (e.g. 'c0_', 'c1_').\n",
    "        i (int): Index for dataset (e.g. 0 for first dataset).\n",
    "        func_kws (_type_, optional): Additional keyword arguments to pass to model function. \n",
    "            Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Evaluated function `func` values.\n",
    "    \"\"\"\n",
    "    if func_kws is None:\n",
    "        func_kws = {}\n",
    "\n",
    "    x = np.array(x)\n",
    "\n",
    "    # --- Get ordered function parameters ---\n",
    "    fn_pars = list(inspect.signature(function).parameters.keys())\n",
    "    argnames = fn_pars[1:]  # skip first (x variable)\n",
    "\n",
    "    kwargs = {}\n",
    "    for name in argnames:\n",
    "        param_key = f'{prefix}{name}_{i}'\n",
    "        if param_key in params:\n",
    "            kwargs[name] = params[param_key].value\n",
    "        elif name in func_kws:\n",
    "            kwargs[name] = func_kws[name]\n",
    "        # else: leave default\n",
    "        else:\n",
    "            pass # IS THIS OKAY!?\n",
    "\n",
    "    return func(x, **kwargs)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4da776",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    def __init__(self, prefix_on=False, **kws):\n",
    "        self._prefix_on = prefix_on\n",
    "        for key, val in kws.items():\n",
    "            setattr(self, key, val)\n",
    "\n",
    "    @property\n",
    "    def prefix_on(self):\n",
    "        return self._prefix_on\n",
    "\n",
    "    @prefix_on.setter\n",
    "    def prefix_on(self, value):\n",
    "        self._prefix_on = bool(value)\n",
    "\n",
    "\n",
    "obj = MyClass(name=\"MUHAMMAD\", age=30, active=True)\n",
    "\n",
    "# print(obj.name)   # → \"MUHAMMAD\"\n",
    "# print(obj.age)    # → 30\n",
    "# print(obj.active) # → True\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
